{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIcmOacShy-p",
    "outputId": "e47e6328-6477-4d52-d914-4dbf25f7fb6b"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD3cPbsJhy-r"
   },
   "source": [
    "# Measuring Effects of Data shifts in CBMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwclGfwnhy-s"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYPJQZB-hy-t"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import concepts_xai\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktrTSqfchy-u"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Set seeds up for reproducibility\n",
    "################################################################################\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(87)\n",
    "tf.random.set_seed(87)\n",
    "np.random.seed(87)\n",
    "random.seed(87)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "## Global Variables Defining Experiment Flow\n",
    "################################################################################\n",
    "\n",
    "_LATEX_SYMBOL = \"$\"  # Change to \"$\" if working out of server\n",
    "USE_DSPRITES = True\n",
    "if USE_DSPRITES:\n",
    "    RESULTS_DIR = \"robustness_results/dsprites\"\n",
    "    DATASETS_DIR = os.path.join(\"results/dsprites\", \"datasets/\")\n",
    "else:\n",
    "    RESULTS_DIR = \"robustness_results/shapes3d\"\n",
    "    DATASETS_DIR = os.path.join(\"results/shapes3d\", \"datasets/\")\n",
    "    \n",
    "Path(DATASETS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "rc('text', usetex=(_LATEX_SYMBOL == \"$\"))\n",
    "plt.style.use('seaborn-whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_results(results_dict, results_dir):\n",
    "    for result_name, result_arr in results_dict.items():\n",
    "        np.savez(\n",
    "            os.path.join(results_dir, f\"{result_name}_means.npz\"),\n",
    "            *list(map(\n",
    "                lambda x: x[0] if isinstance(x[0], np.ndarray) else np.array(x[0]),\n",
    "                result_arr\n",
    "            )),\n",
    "        )\n",
    "        np.savez(\n",
    "            os.path.join(results_dir, f\"{result_name}_stds.npz\"),\n",
    "            *list(map(\n",
    "                lambda x: x[1] if isinstance(x[1], np.ndarray) else np.array(x[1]),\n",
    "                result_arr\n",
    "            )),\n",
    "        )\n",
    "\n",
    "def serialize_experiment_config(config, results_dir):\n",
    "    with open(\n",
    "        os.path.join(results_dir, \"config.yaml\"),\n",
    "        'w',\n",
    "    ) as f:\n",
    "        f.write(yaml.dump(config, sort_keys=True))\n",
    "\n",
    "def deserialize_experiment_config(results_dir):\n",
    "    with open(os.path.join(results_dir, \"config.yaml\"), 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "    \n",
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "    \n",
    "    Modified from https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (N, M).\n",
    "    row_labels\n",
    "        A list or array of length N with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length M with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.tick_params(labelsize=15)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\", fontsize=25)\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels, fontsize=25)\n",
    "    ax.set_yticklabels(row_labels, fontsize=25)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(\n",
    "        top=True,\n",
    "        bottom=False,\n",
    "        labeltop=True,\n",
    "        labelbottom=False,\n",
    "    )\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=-30,\n",
    "        ha=\"right\",\n",
    "        rotation_mode=\"anchor\",\n",
    "    )\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.grid(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=(\"black\", \"white\"),\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "    \n",
    "    Modified from https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A pair of colors.  The first is used for values below a threshold,\n",
    "        the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) <= threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), fontsize=15, **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "def bold_text(x):\n",
    "    if _LATEX_SYMBOL == \"$\":\n",
    "        return r\"$\\textbf{\" + x + \"}$\"\n",
    "    return x\n",
    "\n",
    "def normalize_purity(purity, n_concepts):\n",
    "    return purity / (n_concepts / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRdZhyY9hy-v"
   },
   "source": [
    "## Dependency Tasks Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDLX8kTIhy-v"
   },
   "outputs": [],
   "source": [
    "if not USE_DSPRITES:\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    shapes3d_train_ds = tfds.load('shapes3d', split='train', shuffle_files=True)\n",
    "else:\n",
    "    import concepts_xai.datasets.dSprites as dsprites\n",
    "    import concepts_xai.datasets.latentFactorData as latentFactorData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def relabel_categorical(x):\n",
    "    if len(x.shape) == 1:\n",
    "        _, unique_inds = np.unique(\n",
    "            x,\n",
    "            return_inverse=True,\n",
    "        )\n",
    "        return unique_inds\n",
    "    \n",
    "    result = x[:, :]\n",
    "    for i in range(x.shape[-1]):\n",
    "        _, unique_inds = np.unique(\n",
    "            x[:, i],\n",
    "            return_inverse=True,\n",
    "        )\n",
    "        result[:, i] = unique_inds\n",
    "    return result\n",
    "\n",
    "def cardinality_encoding(card_group_1, card_group_2):\n",
    "    result_to_encoding = {}\n",
    "    for i in card_group_1:\n",
    "        for j in card_group_2:\n",
    "            result_to_encoding[(i, j)] = len(result_to_encoding)\n",
    "    return result_to_encoding\n",
    "\n",
    "def extract_data(\n",
    "    filter_fn,\n",
    "    sample_map_fn=lambda x: x,\n",
    "    concept_map_fn=lambda x: x,\n",
    "    step=1,\n",
    "    label_fn=lambda ex: ex['label_shape'] * 8 + ex['label_scale'],\n",
    "    dataset_path=None,\n",
    "    force_rerun=False,\n",
    "):\n",
    "    if (not force_rerun) and dataset_path and os.path.exists(dataset_path):\n",
    "        # Them time to load up this dataset!\n",
    "        ds = np.load(dataset_path)\n",
    "        return ds[\"X\"], ds[\"y\"], ds[\"c\"]\n",
    "    num_entries = len(shapes3d_train_ds)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    c_train = []\n",
    "    for i, ex in enumerate(tfds.as_numpy(\n",
    "        shapes3d_train_ds.shuffle(buffer_size=15000)\n",
    "    )):\n",
    "        if i % step != 0:\n",
    "            continue\n",
    "        concepts = [\n",
    "            ex['label_floor_hue'],\n",
    "            ex['label_wall_hue'],\n",
    "            ex['label_object_hue'],\n",
    "            ex['label_scale'],\n",
    "            ex['label_shape'],\n",
    "            ex['label_orientation'],\n",
    "        ]\n",
    "        if not filter_fn(concepts):\n",
    "            continue\n",
    "        print(i, end=\"\\r\")\n",
    "\n",
    "        x_train.append(sample_map_fn(ex['image']))\n",
    "        y_train.append(label_fn(ex))\n",
    "        c_train.append(concept_map_fn(concepts))\n",
    "    x_train = np.stack(x_train, axis=0) / 255.0\n",
    "    y_train = relabel_categorical(np.stack(y_train, axis=0))\n",
    "    c_train = relabel_categorical(np.stack(c_train, axis=0))\n",
    "    if dataset_path:\n",
    "        # Then serialize it to speed up things next time\n",
    "        np.savez(\n",
    "            dataset_path,\n",
    "            X=x_train,\n",
    "            y=y_train,\n",
    "            c=c_train,\n",
    "        )\n",
    "    return x_train, y_train, c_train\n",
    "\n",
    "\n",
    "def generate_dsprites_dataset(\n",
    "    label_fn,\n",
    "    filter_fn=None,\n",
    "    dataset_path=None,\n",
    "    concept_map_fn=lambda x: x,\n",
    "    sample_map_fn=lambda x: x,\n",
    "    dsprites_path=\"dsprites/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\",\n",
    "    force_reload=False,\n",
    "):\n",
    "    if (not force_reload) and dataset_path and os.path.exists(dataset_path):\n",
    "        # Them time to load up this dataset!\n",
    "        ds = np.load(dataset_path)\n",
    "        return (\n",
    "            (ds[\"x_train\"], ds[\"y_train\"], ds[\"c_train\"]),\n",
    "            (ds[\"x_test\"], ds[\"y_test\"], ds[\"c_test\"])\n",
    "        )\n",
    "    \n",
    "    def _task_fn(x_data, c_data):\n",
    "        return latentFactorData.get_task_data(\n",
    "            x_data=x_data,\n",
    "            c_data=c_data,\n",
    "            label_fn=label_fn,\n",
    "            filter_fn=filter_fn,\n",
    "        )\n",
    "\n",
    "    loaded_dataset = dsprites.dSprites(\n",
    "        dataset_path=dsprites_path,\n",
    "        train_size=0.8,\n",
    "        random_state=42,\n",
    "        task=_task_fn,\n",
    "    )\n",
    "    _, _, _ = loaded_dataset.load_data()\n",
    "\n",
    "    x_train = sample_map_fn(loaded_dataset.x_train)\n",
    "    y_train = loaded_dataset.y_train\n",
    "    c_train = concept_map_fn(loaded_dataset.c_train)\n",
    "    \n",
    "    x_test = sample_map_fn(loaded_dataset.x_test)\n",
    "    y_test = loaded_dataset.y_test\n",
    "    c_test = concept_map_fn(loaded_dataset.c_test)\n",
    "    \n",
    "    if dataset_path:\n",
    "        # Then serialize it to speed up things next time\n",
    "        np.savez(\n",
    "            dataset_path,\n",
    "            x_train=x_train,\n",
    "            y_train=y_train,\n",
    "            c_train=c_train,\n",
    "            x_test=x_test,\n",
    "            y_test=y_test,\n",
    "            c_test=c_test,\n",
    "        )\n",
    "    return (x_train, y_train, c_train), (x_test, y_test, c_test),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_DSPRITES:\n",
    "    ############################################################################\n",
    "    ## Construct a binary concept task in the shapes3D dataset \n",
    "    ############################################################################\n",
    "    def count_class_balance(y):\n",
    "        one_hot = tf.keras.utils.to_categorical(y)\n",
    "        return np.sum(one_hot, axis=0) / one_hot.shape[0]\n",
    "\n",
    "    def multiclass_task_bin_concepts_map_fn(concepts):\n",
    "        return [\n",
    "            int(concepts[0] < 5),\n",
    "            int(concepts[1] < 5),\n",
    "            int(concepts[2] < 5),\n",
    "            int(concepts[3] < 4),\n",
    "            int(concepts[4] < 2),\n",
    "            int(concepts[5] < 7),\n",
    "        ]\n",
    "\n",
    "\n",
    "    def multiclass_task_bin_concepts_label_fn(concept_dict):\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn([\n",
    "            concept_dict['label_floor_hue'],\n",
    "            concept_dict['label_wall_hue'],\n",
    "            concept_dict['label_object_hue'],\n",
    "            concept_dict['label_scale'],\n",
    "            concept_dict['label_shape'],\n",
    "            concept_dict['label_orientation'],\n",
    "        ])\n",
    "        binary_label_encoding = [\n",
    "            concept_vector[0] or concept_vector[1],\n",
    "            concept_vector[2] or concept_vector[3],\n",
    "            concept_vector[4] or concept_vector[5],\n",
    "        ]\n",
    "        return int(\n",
    "            \"\".join(list(map(str, binary_label_encoding))),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    def filter_fn_dep_0(concept):\n",
    "        ranges = [\n",
    "            list(range(0, 10, 2)),\n",
    "            list(range(0, 10, 2)),\n",
    "            list(range(0, 10, 2)),\n",
    "            list(range(0, 8)),\n",
    "            list(range(4)),\n",
    "            list(range(0, 15, 4)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn(concept)\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        return all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "    floor_hue_wall_hue_sets_lower = [\n",
    "        list(np.random.permutation(7))[:5]\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "\n",
    "    floor_hue_wall_hue_sets_upper = [\n",
    "        list(3 + np.random.permutation(7))[:5]\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "\n",
    "    def filter_fn_dep_1(concept):\n",
    "        ranges = [\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10, 2)),\n",
    "            list(range(0, 10, 2)),\n",
    "            list(range(0, 8)),\n",
    "            list(range(4)),\n",
    "            list(range(0, 15, 4)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "        if concept[0] < 5:\n",
    "            return concept[1] in floor_hue_wall_hue_sets_lower[concept[0]]\n",
    "        else:\n",
    "            return (concept[1] in floor_hue_wall_hue_sets_upper[concept[0]])\n",
    "\n",
    "\n",
    "        wall_hue_object_hue_sets_lower = [\n",
    "        list(np.random.permutation(7))[:5]\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "    wall_hue_object_hue_sets_upper = [\n",
    "        list(3 + np.random.permutation(7))[:5]\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "\n",
    "    def filter_fn_dep_2(concept):\n",
    "        ranges = [\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10, 2)),\n",
    "            list(range(0, 8)),\n",
    "            list(range(4)),\n",
    "            list(range(0, 15, 4)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn(concept)\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "\n",
    "        if (concept[0] < 5):\n",
    "            if concept[1] not in floor_hue_wall_hue_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[1] not in floor_hue_wall_hue_sets_upper[concept[0]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[1] < 5):\n",
    "            if concept[2] not in wall_hue_object_hue_sets_lower[concept[1]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[2] not in wall_hue_object_hue_sets_upper[concept[1]]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "        object_hue_scale_sets_lower = [\n",
    "        list(np.random.permutation(6))[:4]\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "\n",
    "    object_hue_scale_sets_upper = [\n",
    "        list(2 + np.random.permutation(6))[:4]\n",
    "        for _ in range(10)\n",
    "    ]\n",
    "\n",
    "    def filter_fn_dep_3(concept):\n",
    "        ranges = [\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 8)),\n",
    "            list(range(4)),\n",
    "            list(range(0, 15, 4)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "\n",
    "        if (concept[0] < 5):\n",
    "            if concept[1] not in floor_hue_wall_hue_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[1] not in floor_hue_wall_hue_sets_upper[concept[0]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[1] < 5):\n",
    "            if concept[2] not in wall_hue_object_hue_sets_lower[concept[1]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[2] not in wall_hue_object_hue_sets_upper[concept[1]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[2] < 5):\n",
    "            if concept[3] not in object_hue_scale_sets_lower[concept[2]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[3] not in object_hue_scale_sets_upper[concept[2]]):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    scale_shape_sets_lower = [\n",
    "        list(np.random.permutation(3))[:2]\n",
    "        for _ in range(8)\n",
    "    ]\n",
    "\n",
    "    scale_shape_sets_upper = [\n",
    "        list(1 + np.random.permutation(3))[:2]\n",
    "        for _ in range(8)\n",
    "    ]\n",
    "\n",
    "    def filter_fn_dep_4(concept):\n",
    "        ranges = [\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 8)),\n",
    "            list(range(4)),\n",
    "            list(range(0, 15, 2)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "\n",
    "        if (concept[0] < 5):\n",
    "            if concept[1] not in floor_hue_wall_hue_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[1] not in floor_hue_wall_hue_sets_upper[concept[0]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[1] < 5):\n",
    "            if concept[2] not in wall_hue_object_hue_sets_lower[concept[1]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[2] not in wall_hue_object_hue_sets_upper[concept[1]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[2] < 5):\n",
    "            if concept[3] not in object_hue_scale_sets_lower[concept[2]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[3] not in object_hue_scale_sets_upper[concept[2]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[3] < 4):\n",
    "            if concept[4] not in scale_shape_sets_lower[concept[3]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[4] not in scale_shape_sets_upper[concept[3]]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    shape_rotation_sets_lower = [\n",
    "        list(np.random.permutation(9))[:7]\n",
    "        for _ in range(4)\n",
    "    ]\n",
    "\n",
    "    shape_rotation_sets_upper = [\n",
    "        list(6 + np.random.permutation(9))[:7]\n",
    "        for _ in range(4)\n",
    "    ]\n",
    "\n",
    "    def filter_fn_dep_5(concept):\n",
    "        ranges = [\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 10)),\n",
    "            list(range(0, 8)),\n",
    "            list(range(4)),\n",
    "            list(range(0, 15)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "\n",
    "        if (concept[0] < 5):\n",
    "            if concept[1] not in floor_hue_wall_hue_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[1] not in floor_hue_wall_hue_sets_upper[concept[0]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[1] < 5):\n",
    "            if concept[2] not in wall_hue_object_hue_sets_lower[concept[1]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[2] not in wall_hue_object_hue_sets_upper[concept[1]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[2] < 5):\n",
    "            if concept[3] not in object_hue_scale_sets_lower[concept[2]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[3] not in object_hue_scale_sets_upper[concept[2]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[3] < 4):\n",
    "            if concept[4] not in scale_shape_sets_lower[concept[3]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[4] not in scale_shape_sets_upper[concept[3]]):\n",
    "                return False\n",
    "\n",
    "        if (concept[4] < 2):\n",
    "            if concept[5] not in shape_rotation_sets_lower[concept[4]]:\n",
    "                return False\n",
    "        else:\n",
    "            if (concept[5] not in shape_rotation_sets_upper[concept[4]]):\n",
    "                return False\n",
    "        return True\n",
    "else:\n",
    "    def count_class_balance(y):\n",
    "        one_hot = tf.keras.utils.to_categorical(y)\n",
    "        return np.sum(one_hot, axis=0) / one_hot.shape[0]\n",
    "\n",
    "    def multiclass_binary_concepts_map_fn(concepts):\n",
    "        new_concepts = np.zeros((concepts.shape[0], 5))\n",
    "        # We will have 5 concepts:\n",
    "        # (0) \"is it ellipse or square?\"\n",
    "        new_concepts[:, 0] = (concepts[:, 0] < 2).astype(np.int)\n",
    "\n",
    "        # (1) \"is_size < 3?\"\n",
    "        num_sizes = len(set(concepts[:, 1]))\n",
    "        new_concepts[:, 1] = (concepts[:, 1] < num_sizes/2).astype(np.int)\n",
    "\n",
    "        # (2) \"is rotation < PI/2?\"\n",
    "        num_rots = len(set(concepts[:, 2]))\n",
    "        new_concepts[:, 2] = (concepts[:, 2] < num_rots/2).astype(np.int)\n",
    "\n",
    "        # (3) \"is x <= 16?\"\n",
    "        num_x_coords = len(set(concepts[:, 3]))\n",
    "        new_concepts[:, 3] = (concepts[:, 3] < num_x_coords // 2).astype(np.int)\n",
    "\n",
    "        # (4) \"is y <= 16?\"\n",
    "        num_y_coords = len(set(concepts[:, 4]))\n",
    "        new_concepts[:, 4] = (concepts[:, 4] < num_y_coords // 2).astype(np.int)\n",
    "\n",
    "        return new_concepts\n",
    "\n",
    "    def _get_concept_vector(c_data):\n",
    "        return np.array([\n",
    "            # First check if it is an ellipse or a square\n",
    "            int(c_data[0] < 2),\n",
    "            # Now check that it is \"small\"\n",
    "            int(c_data[1] < 3),\n",
    "            # And it has not been rotated more than PI/2 radians\n",
    "            int(c_data[2] < 20),\n",
    "            # Finally, check whether it is in not in the the upper-left quadrant\n",
    "            int(c_data[3] < 15),\n",
    "            int(c_data[4] < 15),\n",
    "        ])\n",
    "\n",
    "    def multiclass_task_label_fn(c_data):\n",
    "        # Our task will be a binary task where we are interested in determining\n",
    "        # whether an image is a \"small\" ellipse not in the upper-left\n",
    "        # quadrant that has been rotated less than 3*PI/2 radians\n",
    "        concept_vector = _get_concept_vector(c_data)\n",
    "        binary_label_encoding = [\n",
    "            concept_vector[0] or concept_vector[1],\n",
    "            concept_vector[2] or concept_vector[3],\n",
    "            concept_vector[4],\n",
    "        ]\n",
    "        return int(\n",
    "            \"\".join(list(map(str, binary_label_encoding))),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    def dep_0_filter_fn(concept):\n",
    "        ranges = [\n",
    "            list(range(3)),\n",
    "            list(range(0, 6, 2)),\n",
    "            list(range(0, 40, 4)),\n",
    "            list(range(0, 32, 2)),\n",
    "            list(range(0, 32, 2)),\n",
    "        ]\n",
    "        return all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "    scale_shape_sets_lower = [\n",
    "        list(np.random.permutation(4))[:3] for i in range(3)\n",
    "    ]\n",
    "\n",
    "    scale_shape_sets_upper = [\n",
    "        list(2 + np.random.permutation(4))[:3] for i in range(3)\n",
    "    ]\n",
    "    def dep_1_filter_fn(concept):\n",
    "        ranges = [\n",
    "            list(range(3)),\n",
    "            list(range(6)),\n",
    "            list(range(0, 40, 4)),\n",
    "            list(range(0, 32, 2)),\n",
    "            list(range(0, 32, 2)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = _get_concept_vector(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "        if concept_vector[0]:\n",
    "            if concept[1] not in scale_shape_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[0] not in scale_shape_sets_upper[concept[0]]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    rotation_scale_sets_lower = [\n",
    "        list(np.random.permutation(30))[:20] for i in range(6)\n",
    "    ]\n",
    "\n",
    "    rotation_scale_sets_upper = [\n",
    "        list(10 + np.random.permutation(30))[:20] for i in range(6)\n",
    "    ]\n",
    "    def dep_2_filter_fn(concept):\n",
    "        ranges = [\n",
    "            list(range(3)),\n",
    "            list(range(6)),\n",
    "            list(range(0, 40, 2)),\n",
    "            list(range(0, 32, 2)),\n",
    "            list(range(0, 32, 2)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = _get_concept_vector(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "        if concept_vector[0]:\n",
    "            if concept[1] not in scale_shape_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[0] not in scale_shape_sets_upper[concept[0]]:\n",
    "                return False\n",
    "\n",
    "        if concept_vector[1]:\n",
    "            if concept[2] not in rotation_scale_sets_lower[concept[1]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[2] not in rotation_scale_sets_upper[concept[1]]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    x_pos_rotation_sets_lower = [\n",
    "        list(np.random.permutation(20))[:16]\n",
    "        for i in range(40)\n",
    "    ]\n",
    "\n",
    "    x_pos_rotation_sets_upper = [\n",
    "        list(12 + np.random.permutation(20))[:16]\n",
    "        for i in range(40)\n",
    "    ]\n",
    "    def dep_3_filter_fn(concept):\n",
    "        ranges = [\n",
    "            list(range(3)),\n",
    "            list(range(6)),\n",
    "            list(range(0, 40, 2)),\n",
    "            list(range(0, 32)),\n",
    "            list(range(0, 32, 2)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = _get_concept_vector(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "        if concept_vector[0]:\n",
    "            if concept[1] not in scale_shape_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[0] not in scale_shape_sets_upper[concept[0]]:\n",
    "                return False\n",
    "\n",
    "        if concept_vector[1]:\n",
    "            if concept[2] not in rotation_scale_sets_lower[concept[1]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[2] not in rotation_scale_sets_upper[concept[1]]:\n",
    "                return False\n",
    "\n",
    "        if concept_vector[2]:\n",
    "            if concept[3] not in x_pos_rotation_sets_lower[concept[2]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[3] not in x_pos_rotation_sets_upper[concept[2]]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    y_pos_x_pos_sets_lower = [\n",
    "        list(np.random.permutation(20))[:16]\n",
    "        for i in range(32)\n",
    "    ]\n",
    "\n",
    "    y_pos_x_pos_sets_upper = [\n",
    "        list(12 + np.random.permutation(20))[:16]\n",
    "        for i in range(32)\n",
    "    ]\n",
    "    def dep_4_filter_fn(concept):\n",
    "        ranges = [\n",
    "            list(range(3)),\n",
    "            list(range(6)),\n",
    "            list(range(0, 40, 2)),\n",
    "            list(range(0, 32)),\n",
    "            list(range(0, 32)),\n",
    "        ]\n",
    "\n",
    "        concept_vector = _get_concept_vector(concept)\n",
    "\n",
    "        # First filter as in small dataset to constraint the size of the data a bit\n",
    "        if not all([\n",
    "            (concept[i] in ranges[i]) for i in range(len(ranges))\n",
    "        ]):\n",
    "            return False\n",
    "        if concept_vector[0]:\n",
    "            if concept[1] not in scale_shape_sets_lower[concept[0]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[0] not in scale_shape_sets_upper[concept[0]]:\n",
    "                return False\n",
    "\n",
    "        if concept_vector[1]:\n",
    "            if concept[2] not in rotation_scale_sets_lower[concept[1]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[2] not in rotation_scale_sets_upper[concept[1]]:\n",
    "                return False\n",
    "\n",
    "        if concept_vector[2]:\n",
    "            if concept[3] not in x_pos_rotation_sets_lower[concept[2]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[3] not in x_pos_rotation_sets_upper[concept[2]]:\n",
    "                return False\n",
    "\n",
    "        if concept_vector[3]:\n",
    "            if concept[4] not in y_pos_x_pos_sets_lower[concept[3]]:\n",
    "                return False\n",
    "        else:\n",
    "            if concept[4] not in y_pos_x_pos_sets_upper[concept[3]]:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_FORCE_RERUN = False\n",
    "if not USE_DSPRITES:\n",
    "    _FORCE_RERUN = False\n",
    "if not USE_DSPRITES:\n",
    "    def balanced_multiclass_task_bin_concepts_label_fn(concept_dict):\n",
    "        concept_vector = multiclass_task_bin_concepts_map_fn([\n",
    "            concept_dict['label_floor_hue'],\n",
    "            concept_dict['label_wall_hue'],\n",
    "            concept_dict['label_object_hue'],\n",
    "            concept_dict['label_scale'],\n",
    "            concept_dict['label_shape'],\n",
    "            concept_dict['label_orientation'],\n",
    "        ])\n",
    "        if concept_vector[4] == 0:\n",
    "            offset = 0\n",
    "            binary_label_encoding = [\n",
    "                concept_vector[0],\n",
    "                concept_vector[1],\n",
    "            ]\n",
    "        else:\n",
    "            offset = 4\n",
    "            binary_label_encoding = [\n",
    "                concept_vector[2],\n",
    "                concept_vector[3],\n",
    "                concept_vector[5],\n",
    "            ]\n",
    "\n",
    "        return offset + int(\n",
    "            \"\".join(list(map(str, binary_label_encoding))),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    data_x_train, data_y_train, data_c_train = extract_data(\n",
    "        filter_fn_dep_0,\n",
    "        dataset_path=os.path.join(DATASETS_DIR, \"balanced_multiclass_task_bin_concepts_dep_0_concepts.npz\"),\n",
    "        concept_map_fn=multiclass_task_bin_concepts_map_fn,\n",
    "        label_fn=balanced_multiclass_task_bin_concepts_label_fn,\n",
    "        force_rerun=_FORCE_RERUN,\n",
    "    )\n",
    "\n",
    "    data_x_train, data_x_test, data_y_train, data_y_test, data_c_train, data_c_test = train_test_split(\n",
    "        data_x_train,\n",
    "        data_y_train,\n",
    "        data_c_train,\n",
    "        test_size=0.2,\n",
    "    )\n",
    "\n",
    "    print(\"data_x_train.shape =\", data_x_train.shape)\n",
    "    print(\"data_x_train label distribution:\", count_class_balance(data_y_train))\n",
    "    print(\"data_x_train concept distribution:\", np.sum(data_c_train, axis=0)/data_c_train.shape[0])\n",
    "    print(\"data_x_train exclusive concept distribution:\", np.sum(data_c_train[np.sum(data_c_train, axis=-1) == 1], axis=0)/data_c_train.shape[0])\n",
    "    print(\"data_x_test.shape =\", data_x_test.shape)\n",
    "    print(\"data_c_test.shape =\", data_c_test.shape)\n",
    "    data_train = (data_x_train, data_y_train, data_c_train)\n",
    "    data_test = (data_x_test, data_y_test, data_c_test)\n",
    "\n",
    "    dep_0_corr_mat = np.ones(\n",
    "        (\n",
    "            data_train[2].shape[-1],\n",
    "            len(set(data_train[1]))\n",
    "        )\n",
    "    )\n",
    "    for c in range(dep_0_corr_mat.shape[0]):\n",
    "        for l in range(dep_0_corr_mat.shape[1]):\n",
    "            dep_0_corr_mat[c][l] = np.corrcoef(\n",
    "                data_train[2][:, c],\n",
    "                (data_train[1] == l).astype(np.int32),\n",
    "            )[0, 1]\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "    im, cbar = heatmap(\n",
    "        np.abs(dep_0_corr_mat),\n",
    "        [f\"$c_{i}$\" for i in range(dep_0_corr_mat.shape[0])],\n",
    "        [f\"$l_{i}$\" for i in range(dep_0_corr_mat.shape[1])],\n",
    "        ax=ax,\n",
    "        cmap=\"magma\",\n",
    "        cbarlabel=f\"Correlation Coef\",\n",
    "        vmin=0, #-1,\n",
    "        vmax=1,\n",
    "    )\n",
    "    texts = annotate_heatmap(im, valfmt=\"{x:.2f}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.suptitle(f\"3dshapes Concept-Label Absolute Correlations ($\\lambda = 0$)\", fontsize=25)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\")\n",
    "else:\n",
    "    def balanced_multiclass_task_label_fn(c_data):\n",
    "        # Our task will be a binary task where we are interested in determining\n",
    "        # whether an image is a \"small\" ellipse not in the upper-left\n",
    "        # quadrant that has been rotated less than 3*PI/2 radians\n",
    "        concept_vector = _get_concept_vector(c_data)\n",
    "        threshold = 0\n",
    "        if concept_vector[0] == 1:\n",
    "            binary_label_encoding = [\n",
    "                concept_vector[1],\n",
    "                concept_vector[2],\n",
    "            ]\n",
    "        else:\n",
    "            threshold = 4\n",
    "            binary_label_encoding = [\n",
    "                concept_vector[3],\n",
    "                concept_vector[4],\n",
    "            ]\n",
    "        return threshold + int(\n",
    "            \"\".join(list(map(str, binary_label_encoding))),\n",
    "            2\n",
    "        )\n",
    "    \n",
    "    def robust_label_example(c_data):\n",
    "        concept_vector = _get_concept_vector(c_data)\n",
    "        return np.sum(concept_vector)\n",
    "\n",
    "    data_train, data_test = generate_dsprites_dataset(\n",
    "        label_fn=balanced_multiclass_task_label_fn,\n",
    "        filter_fn=dep_0_filter_fn,\n",
    "        dataset_path=os.path.join(DATASETS_DIR, \"balanced_multiclass_task_bin_concepts_dep_0_complete_dataset.npz\"),\n",
    "        dsprites_path=\"dsprites/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\",\n",
    "        concept_map_fn=multiclass_binary_concepts_map_fn,\n",
    "    #     force_reload=True,\n",
    "    )\n",
    "\n",
    "    dep_0_corr_mat = np.ones(\n",
    "        (\n",
    "            data_train[2].shape[-1],\n",
    "            len(set(data_train[1]))\n",
    "        )\n",
    "    )\n",
    "    for c in range(dep_0_corr_mat.shape[0]):\n",
    "        for l in range(dep_0_corr_mat.shape[1]):\n",
    "            dep_0_corr_mat[c][l] = np.corrcoef(\n",
    "                data_train[2][:, c],\n",
    "                (data_train[1] == l).astype(np.int32),\n",
    "            )[0, 1]\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "    im, cbar = heatmap(\n",
    "        np.abs(dep_0_corr_mat),\n",
    "        [f\"$c_{i}$\" for i in range(dep_0_corr_mat.shape[0])],\n",
    "        [f\"$l_{i}$\" for i in range(dep_0_corr_mat.shape[1])],\n",
    "        ax=ax,\n",
    "        cmap=\"magma\",\n",
    "        cbarlabel=f\"Correlation Coef\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    texts = annotate_heatmap(im, valfmt=\"{x:.2f}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.suptitle(f\"dSprites Concept-Label Absolute Correlations ($\\lambda = 0$)\", fontsize=25)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"data_dataset train size:\", data_train[0].shape[0])\n",
    "    print(\"data_dataset train concept size:\", data_train[2].shape)\n",
    "    print(\"\\tTrain balance:\", count_class_balance(data_train[1]))\n",
    "    print(\"\\tConcept balance:\", np.sum(data_train[2], axis=0)/data_train[2].shape[0])\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    robust_data_train, robust_data_test = generate_dsprites_dataset(\n",
    "        label_fn=robust_label_example,\n",
    "        filter_fn=dep_0_filter_fn,\n",
    "        dataset_path=os.path.join(DATASETS_DIR, \"robust_task_bin_concepts_dep_0_dataset.npz\"),\n",
    "        dsprites_path=\"dsprites/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz\",\n",
    "        concept_map_fn=multiclass_binary_concepts_map_fn,\n",
    "    #     force_reload=True,\n",
    "    )\n",
    "\n",
    "    robust_corr_mat = np.ones(\n",
    "        (\n",
    "            robust_data_train[2].shape[-1],\n",
    "            len(set(robust_data_train[1]))\n",
    "        )\n",
    "    )\n",
    "    for c in range(robust_corr_mat.shape[0]):\n",
    "        for l in range(robust_corr_mat.shape[1]):\n",
    "            robust_corr_mat[c][l] = np.corrcoef(\n",
    "                robust_data_train[2][:, c],\n",
    "                (robust_data_train[1] == l).astype(np.int32),\n",
    "            )[0, 1]\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 6))\n",
    "    im, cbar = heatmap(\n",
    "        np.abs(robust_corr_mat),\n",
    "        [f\"$c_{i}$\" for i in range(robust_corr_mat.shape[0])],\n",
    "        [f\"$l_{i}$\" for i in range(robust_corr_mat.shape[1])],\n",
    "        ax=ax,\n",
    "        cmap=\"magma\",\n",
    "        cbarlabel=f\"Correlation Coef\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    texts = annotate_heatmap(im, valfmt=\"{x:.2f}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.suptitle(f\"dSprites Robust Dataset ($\\lambda = 0$)\", fontsize=25)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"robust_data_dataset train size:\", robust_data_train[0].shape[0])\n",
    "    print(\"robust_data_dataset train concept size:\", robust_data_train[2].shape)\n",
    "    print(\"\\tTrain balance:\", count_class_balance(robust_data_train[1]))\n",
    "    print(\"\\tConcept balance:\", np.sum(robust_data_train[2], axis=0)/robust_data_train[2].shape[0])\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wciMdtP9hy-1"
   },
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ey3yb8HIhy-2",
    "outputId": "08bc7f0b-146f-48e5-8f9f-40b608e09cb3"
   },
   "outputs": [],
   "source": [
    "# Construct the encoder model\n",
    "def _extract_concepts(activations, concept_cardinality):\n",
    "    concepts = []\n",
    "    total_seen = 0\n",
    "    if all(np.array(concept_cardinality) <= 2):\n",
    "        # Then nothing to do here as they are all binary concepts\n",
    "        return activations\n",
    "    for num_values in concept_cardinality:\n",
    "        concepts.append(activations[:, total_seen: total_seen + num_values])\n",
    "        total_seen += num_values\n",
    "    return concepts\n",
    "    \n",
    "def construct_encoder(\n",
    "    input_shape,\n",
    "    filter_groups,\n",
    "    units,\n",
    "    concept_cardinality,\n",
    "    drop_prob=0.5,\n",
    "    max_pool_window=(2,2),\n",
    "    max_pool_stride=2,\n",
    "    latent_dims=0,\n",
    "    output_logits=False,\n",
    "):\n",
    "    encoder_inputs = tf.keras.Input(shape=input_shape)\n",
    "    encoder_compute_graph = encoder_inputs\n",
    "    \n",
    "    # Start with our convolutions\n",
    "    num_convs = 0\n",
    "    for filter_group in filter_groups:\n",
    "        for (num_filters, kernel_size) in filter_group:\n",
    "            encoder_compute_graph = tf.keras.layers.Conv2D(\n",
    "                filters=num_filters,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=\"SAME\",\n",
    "                activation=None,\n",
    "                name=f'encoder_conv_{num_convs}',\n",
    "            )(encoder_compute_graph)\n",
    "            num_convs += 1\n",
    "            encoder_compute_graph = tf.keras.layers.BatchNormalization()(\n",
    "                encoder_compute_graph\n",
    "            )\n",
    "            encoder_compute_graph = tf.keras.activations.relu(encoder_compute_graph)\n",
    "        # Then do a max pool here to control the parameter count of the model\n",
    "        # at the end of each group\n",
    "        encoder_compute_graph = tf.keras.layers.MaxPooling2D(\n",
    "            pool_size=max_pool_window,\n",
    "            strides=max_pool_stride,\n",
    "        )(\n",
    "            encoder_compute_graph\n",
    "        )\n",
    "    \n",
    "    # Flatten this guy\n",
    "    encoder_compute_graph = tf.keras.layers.Flatten()(encoder_compute_graph)\n",
    "    \n",
    "    # Add a dropout if requested\n",
    "    if drop_prob:\n",
    "        encoder_compute_graph = tf.keras.layers.Dropout(drop_prob)(\n",
    "            encoder_compute_graph\n",
    "        )\n",
    "    \n",
    "    # Finally, include the fully connected bottleneck here\n",
    "    for i, units in enumerate(units):\n",
    "        encoder_compute_graph = tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation='relu',\n",
    "            name=f\"encoder_dense_{i}\",\n",
    "        )(encoder_compute_graph)\n",
    "    \n",
    "    if latent_dims:\n",
    "        bypass = tf.keras.layers.Dense(\n",
    "            latent_dims,\n",
    "            activation=\"sigmoid\",\n",
    "            name=\"encoder_bypass_channel\",\n",
    "        )(encoder_compute_graph)\n",
    "    else:\n",
    "        bypass = None\n",
    "    \n",
    "    # Map to our output distribution to a flattened\n",
    "    # vector where we will extract distributions over\n",
    "    # all concept values\n",
    "    encoder_compute_graph = tf.keras.layers.Dense(\n",
    "        sum(concept_cardinality),\n",
    "        activation=None,\n",
    "        name=\"encoder_concept_outputs\",\n",
    "    )(encoder_compute_graph)\n",
    "        \n",
    "    # Separate this vector into all of its heads\n",
    "    concept_outputs = _extract_concepts(\n",
    "        encoder_compute_graph,\n",
    "        concept_cardinality,\n",
    "    )\n",
    "    if not output_logits:\n",
    "        if isinstance(concept_outputs, list):\n",
    "            for i, concept_vec in enumerate(concept_outputs):\n",
    "                if concept_vec.shape[-1] == 1:\n",
    "                    # Then this is a binary concept so simply apply sigmoid\n",
    "                    concept_outputs[i] = tf.keras.activations.sigmoid(concept_vec)\n",
    "                else:\n",
    "                    # Else we will apply a softmax layer as we assume that all of these\n",
    "                    # entries represent a multi-modal probability distribution\n",
    "                    concept_outputs[i] = tf.keras.activations.softmax(\n",
    "                        concept_vec,\n",
    "                        axis=-1,\n",
    "                    )\n",
    "        else:\n",
    "            # Else they are allbinary concepts so let's sigmoid them\n",
    "            concept_outputs = tf.keras.activations.sigmoid(concept_outputs)\n",
    "    return tf.keras.Model(\n",
    "        encoder_inputs,\n",
    "        [concept_outputs, bypass] if bypass is not None else concept_outputs,\n",
    "        name=\"encoder\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7lu1IS3hy-4"
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "## Build concepts-to-labels model\n",
    "############################################################################\n",
    "\n",
    "def construct_decoder(units, num_outputs):\n",
    "    decoder_layers = [tf.keras.layers.Flatten()] + [\n",
    "        tf.keras.layers.Dense(\n",
    "            units,\n",
    "            activation=tf.nn.relu,\n",
    "            name=f\"decoder_dense_{i+1}\",\n",
    "        ) for i, units in enumerate(units)\n",
    "    ]\n",
    "    return tf.keras.Sequential(decoder_layers + [\n",
    "        tf.keras.layers.Dense(\n",
    "            num_outputs if num_outputs > 2 else 1,\n",
    "            activation=None,\n",
    "            name=\"decoder_model_output\",\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjd9d2sDhy-4",
    "outputId": "f8a8faed-079a-475b-d5be-adad132a272d"
   },
   "outputs": [],
   "source": [
    "# Construct the complete model\n",
    "def construct_end_to_end_model(\n",
    "    input_shape,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    num_outputs,\n",
    "    learning_rate=1e-3,\n",
    "):\n",
    "    model_inputs = tf.keras.Input(shape=input_shape)\n",
    "    latent = encoder(model_inputs)\n",
    "    if isinstance(latent, list):\n",
    "        if len(latent) > 1:\n",
    "            compacted_vector = tf.keras.layers.Concatenate(axis=-1)(\n",
    "                latent\n",
    "            )\n",
    "        else:\n",
    "            compacted_vector = latent[0]\n",
    "    else:\n",
    "        compacted_vector = latent\n",
    "    model_compute_graph = decoder(compacted_vector)\n",
    "    # Now time to collapse all the concepts again back into a single vector\n",
    "    model = tf.keras.Model(\n",
    "        model_inputs,\n",
    "        model_compute_graph,\n",
    "        name=\"complete_model\",\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "        loss=(\n",
    "            tf.keras.losses.BinaryCrossentropy(from_logits=True) if (num_outputs <= 2)\n",
    "            else tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        ),\n",
    "        metrics=[\n",
    "            \"binary_accuracy\" if (num_outputs <= 2)\n",
    "            else tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1)\n",
    "        ],\n",
    "    )\n",
    "    return model, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTjkp5B3hy-6",
    "outputId": "35f4b4fe-7295-4747-a9d4-c52f4c75dab3"
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "## Build CBM\n",
    "############################################################################\n",
    "import concepts_xai.methods.CBM.CBModel as CBM\n",
    "\n",
    "def construct_cbm(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    num_outputs,\n",
    "    alpha=0.1,\n",
    "    learning_rate=1e-3,\n",
    "    latent_dims=0,\n",
    "    encoder_output_logits=False,\n",
    "):\n",
    "    model_factory = CBM.BypassJointCBM if latent_dims else CBM.JointConceptBottleneckModel\n",
    "    cbm_model = model_factory(\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        task_loss=(\n",
    "            tf.keras.losses.BinaryCrossentropy(from_logits=True) if (num_outputs <= 2)\n",
    "            else tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        ),\n",
    "        name=\"joint_cbm\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy() if (num_outputs <= 2)\n",
    "            else tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1)\n",
    "        ],\n",
    "        alpha=alpha,\n",
    "        pass_concept_logits=encoder_output_logits,\n",
    "    )\n",
    "\n",
    "    ############################################################################\n",
    "    ## Compile CBM Model\n",
    "    ############################################################################\n",
    "\n",
    "    cbm_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    )\n",
    "    return cbm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_image_color_random(sample, y, prob=0.75):\n",
    "    width, height = sample.shape[0:2]\n",
    "    result = sample.copy()\n",
    "    if np.random.choice([False, True], p=[1-prob, prob]):\n",
    "        mask = result == 0\n",
    "        return result + mask * y * 0.1\n",
    "    return result\n",
    "\n",
    "def corrupt_dataset_color_random(x, y):\n",
    "    new_x = x.copy()\n",
    "    for i, sample in enumerate(new_x):\n",
    "        new_x[i, :] = corrupt_image_color_random(sample, y[i])\n",
    "    return new_x\n",
    "\n",
    "color_random_corrupted_data_train = corrupt_dataset_color_random(data_train[0], data_train[1]), data_train[1], data_train[2]\n",
    "color_random_corrupted_data_test = corrupt_dataset_color_random(data_test[0], data_test[1]), data_test[1], data_test[2]\n",
    "\n",
    "for sample, label, i in zip(color_random_corrupted_data_train[0], color_random_corrupted_data_train[1], range(10)):\n",
    "    print(\"Sample\", i, \"with label\", label)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(sample, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gallery(array, ncols=3):\n",
    "    nindex, height, width, intensity = array.shape\n",
    "    nrows = nindex//ncols\n",
    "    assert nindex == nrows*ncols\n",
    "    # want result.shape = (height*nrows, width*ncols, intensity)\n",
    "    result = (array.reshape(nrows, ncols, height, width, intensity)\n",
    "              .swapaxes(1,2)\n",
    "              .reshape(height*nrows, width*ncols, intensity))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(color_random_corrupted_data_train[1]))\n",
    "images = [None for _ in range(num_classes)]\n",
    "seen_classes = set()\n",
    "for sample, label in zip(*color_random_corrupted_data_train[:-1]):\n",
    "    if label in seen_classes:\n",
    "        continue\n",
    "    seen_classes.add(label)\n",
    "    images[label] = sample\n",
    "    if len(seen_classes) == num_classes:\n",
    "        break\n",
    "\n",
    "plt.grid(False)\n",
    "plt.axis(False)\n",
    "plt.imshow(gallery(np.array(images), ncols=4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concepts_xai.evaluation.metrics.niching as niching\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import scipy\n",
    "import joblib\n",
    "import concepts_xai.evaluation.metrics.purity as purity\n",
    "\n",
    "def construct_trivial_auc_mat(num_concepts):\n",
    "    result = np.ones((num_concepts, num_concepts), dtype=np.float32) * 0.5\n",
    "    return result + np.eye(num_concepts, dtype=np.float32) * 0.5\n",
    "    \n",
    "    \n",
    "def cbm_intervention(\n",
    "    cbm_model,\n",
    "    x_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    c_test,\n",
    "    intervention_concepts,\n",
    "):\n",
    "    # matrix mapping (concept, label) to the value we should set it\n",
    "    # to during an intervention\n",
    "    n_concepts = c_test.shape[-1]\n",
    "    intervention_values = np.zeros((n_concepts, 2))\n",
    "    if cbm_model.pass_concept_logits:\n",
    "        # Then the token value we will use for intervening\n",
    "        # will be based on the percentile of values in the\n",
    "        # training data\n",
    "        c_train_pred = cbm_model.encoder(x_train)\n",
    "        for i in range(n_concepts):\n",
    "            low_percentile, high_percentile = np.percentile(c_train_pred[:, i], [5, 95])\n",
    "            intervention_values[i, 0] = low_percentile\n",
    "            intervention_values[i, 1] = high_percentile\n",
    "    else:\n",
    "        # Else we use hard thresholds of 0 and 1 for everything as we are using\n",
    "        # real probabilities\n",
    "        intervention_values[:, 1] = 1.0\n",
    "    \n",
    "    # Now time to make our concept predictions\n",
    "    c_test_pred = cbm_model.encoder(x_test).numpy()\n",
    "    for int_concept in intervention_concepts:\n",
    "        c_test_pred[:, int_concept] = (\n",
    "            intervention_values[int_concept, 0] * (c_test[:, int_concept] == 0) +\n",
    "            intervention_values[int_concept, 1] * (c_test[:, int_concept] == 1)\n",
    "        )\n",
    "    \n",
    "    # Make the actual task predictions\n",
    "    # Extend c_test_pred so that it has its complement probability as well\n",
    "    y_test_preds = cbm_model.predict_from_concepts(c_test_pred).numpy()\n",
    "    y_test_preds = scipy.special.softmax(y_test_preds, axis=-1)\n",
    "    \n",
    "    # Time to evaluate these predictions\n",
    "    return {\n",
    "        \"accuracy\": sklearn.metrics.accuracy_score(\n",
    "            y_test,\n",
    "            np.argmax(y_test_preds, axis=-1),\n",
    "        ),\n",
    "        \"auc\": sklearn.metrics.roc_auc_score(\n",
    "            tf.keras.utils.to_categorical(y_test),\n",
    "            y_test_preds,\n",
    "            multi_class='ovo',\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    \n",
    "def cbm_mixed_capacity_intervention_experiment_loop(\n",
    "    train_data,\n",
    "    corrupted_train_data,\n",
    "    test_data,\n",
    "    corrupted_test_data,\n",
    "    experiment_config,\n",
    "    load_from_cache=False,\n",
    "):\n",
    "    experiment_variables = dict(\n",
    "        current_experiment_idx=0,\n",
    "        \n",
    "        task_accuracies=[],\n",
    "        task_aucs=[],\n",
    "        concept_accuracies=[],\n",
    "        purity_scores=[],\n",
    "        non_oracle_purity_scores=[],\n",
    "        purity_matrices=[],\n",
    "        oracle_matrices=[],\n",
    "        \n",
    "        intervention_task_accuracies=[],\n",
    "        intervention_task_aucs=[],\n",
    "\n",
    "        niche_impurity_aucs=[],\n",
    "        niche_impurity_by_betas=[],\n",
    "        niche_size_by_betas=[],\n",
    "        \n",
    "        concept_niche_impurity_aucs=[],\n",
    "        concept_niche_impurity_by_betas=[],\n",
    "        concept_niche_size_by_betas=[],\n",
    "        \n",
    "        \n",
    "        \n",
    "        corrupted_task_accuracies=[],\n",
    "        corrupted_task_aucs=[],\n",
    "        corrupted_concept_accuracies=[],\n",
    "        corrupted_purity_scores=[],\n",
    "        corrupted_purity_matrices=[],\n",
    "\n",
    "        corrupted_intervention_task_accuracies=[],\n",
    "        corrupted_intervention_task_aucs=[],\n",
    "\n",
    "        corrupted_niche_impurity_aucs=[],\n",
    "        corrupted_niche_impurity_by_betas=[],\n",
    "        corrupted_niche_size_by_betas=[],\n",
    "        \n",
    "        corrupted_concept_niche_impurity_aucs=[],\n",
    "        corrupted_concept_niche_impurity_by_betas=[],\n",
    "        corrupted_concept_niche_size_by_betas=[],\n",
    "    )\n",
    "    experiment_config[\"data_concepts\"] = experiment_config.get(\n",
    "        \"data_concepts\",\n",
    "        experiment_config[\"num_concepts\"],\n",
    "    )\n",
    "    \n",
    "    Path(\n",
    "        os.path.join(\n",
    "            experiment_config[\"results_dir\"],\n",
    "            \"models\",\n",
    "        )\n",
    "    ).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    x_train, y_train, c_train = train_data\n",
    "    corrupted_x_train, corrupted_y_train, corrupted_c_train = corrupted_train_data\n",
    "    x_test, y_test, c_test = test_data\n",
    "    corrupted_x_test, corrupted_y_test, corrupted_c_test = corrupted_test_data\n",
    "    start_ind = 0\n",
    "    if load_from_cache:\n",
    "        cached = os.path.exists(\n",
    "            os.path.join(experiment_config['results_dir'], 'results.joblib')\n",
    "        )\n",
    "        if cached:\n",
    "            print(\n",
    "                \"Found cached directory at\",\n",
    "                os.path.join(experiment_config['results_dir'], 'results.joblib'),\n",
    "            )\n",
    "            results = joblib.load(\n",
    "                os.path.join(experiment_config['results_dir'], 'results.joblib')\n",
    "            )\n",
    "            start_ind = results['current_experiment_idx']\n",
    "            print(\"\\tStart index is\", start_ind)\n",
    "            complete_cache = start_ind == len(experiment_config[\"alpha_values\"])\n",
    "            for varname in experiment_variables.keys():\n",
    "                if varname == 'current_experiment_idx':\n",
    "                    continue\n",
    "                if (varname not in results):\n",
    "                    print(\"\\tWe could not find variable\", varname, \"in the cache\")\n",
    "                    complete_cache = False\n",
    "                    continue\n",
    "                if len(results[varname]) != start_ind:\n",
    "                    complete_cache = False\n",
    "                    start_ind = min(len(results[varname]), start_ind)\n",
    "            if complete_cache:\n",
    "                # Then we are good to go\n",
    "                if not os.path.exists(\n",
    "                    os.path.join(experiment_config[\"results_dir\"], \"config.yaml\")\n",
    "                ):\n",
    "                    # then serialize the config as this is a different version run\n",
    "                    serialize_experiment_config(\n",
    "                        experiment_config,\n",
    "                        experiment_config[\"results_dir\"],\n",
    "                    )\n",
    "                return results\n",
    "            else:\n",
    "                # Else we have a partial initialization so let's use it\n",
    "                experiment_variables = results\n",
    "    \n",
    "    # Let's save our config here either way\n",
    "    serialize_experiment_config(\n",
    "        experiment_config,\n",
    "        experiment_config[\"results_dir\"],\n",
    "    )\n",
    "    \n",
    "    verbosity = experiment_config.get(\"verbosity\", 0)\n",
    "    for alpha in experiment_config[\"alpha_values\"][start_ind:]:\n",
    "        print(\"Training with alpha:\", alpha)\n",
    "        task_accs = []\n",
    "        concept_accs = []\n",
    "        aucs = []\n",
    "        purity_mats = []\n",
    "        oracle_mats = []\n",
    "        purities = []\n",
    "        non_oracle_purities = []\n",
    "        niche_impurity_aucs = []\n",
    "        niche_impurity_by_betas = []\n",
    "        niche_size_by_betas = []\n",
    "        \n",
    "        concept_niche_impurity_aucs = []\n",
    "        concept_niche_impurity_by_betas = []\n",
    "        concept_niche_size_by_betas = []\n",
    "        \n",
    "        intervention_task_accuracies = []\n",
    "        intervention_task_aucs = []\n",
    "        \n",
    "        corrupted_task_accs = []\n",
    "        corrupted_concept_accs = []\n",
    "        corrupted_aucs = []\n",
    "        corrupted_purity_mats = []\n",
    "        corrupted_purities = []\n",
    "        \n",
    "        corrupted_niche_impurity_aucs = []\n",
    "        corrupted_niche_impurity_by_betas = []\n",
    "        corrupted_niche_size_by_betas = []\n",
    "        \n",
    "        corrupted_concept_niche_impurity_aucs = []\n",
    "        corrupted_concept_niche_impurity_by_betas = []\n",
    "        corrupted_concept_niche_size_by_betas = []\n",
    "        \n",
    "        corrupted_intervention_task_accuracies = []\n",
    "        corrupted_intervention_task_aucs = []\n",
    "        \n",
    "        for trial in range(experiment_config[\"trials\"]):\n",
    "            print(f\"\\tTrial {trial + 1}/{experiment_config['trials']} for alpha\", alpha)\n",
    "            # First proceed to do an end-to-end model in case we want to\n",
    "            # do some task-specific pretraining\n",
    "            encoder_units = experiment_config[\"encoder_units\"]\n",
    "            decoder_units = experiment_config[\"decoder_units\"]\n",
    "            \n",
    "            end_to_end_model, encoder, decoder = construct_end_to_end_model(\n",
    "                input_shape=experiment_config[\"input_shape\"],\n",
    "                num_outputs=experiment_config[\"num_outputs\"],\n",
    "                learning_rate=experiment_config[\"learning_rate\"],\n",
    "                encoder=construct_encoder(\n",
    "                    input_shape=experiment_config[\"input_shape\"],\n",
    "                    filter_groups=experiment_config[\"encoder_filter_groups\"],\n",
    "                    units=encoder_units,\n",
    "                    concept_cardinality=experiment_config[\"concept_cardinality\"],\n",
    "                    drop_prob=experiment_config.get(\"drop_prob\", 0.5),\n",
    "                    max_pool_window=experiment_config.get(\"max_pool_window\", (2, 2)),\n",
    "                    max_pool_stride=experiment_config.get(\"max_pool_stride\", (2, 2)),\n",
    "                    latent_dims=experiment_config.get(\"latent_dims\", 0),\n",
    "                    output_logits=experiment_config.get(\"encoder_output_logits\", False),\n",
    "                ),\n",
    "                decoder=construct_decoder(\n",
    "                    units=decoder_units,\n",
    "                    num_outputs=experiment_config[\"num_outputs\"],\n",
    "                ),\n",
    "            )\n",
    "            \n",
    "            if experiment_config.get(\"pre_train_epochs\"):\n",
    "                print(\"\\tModel pre-training with corrupted samples...\")\n",
    "                end_to_end_model.fit(\n",
    "                    x=corrupted_x_train,\n",
    "                    y=corrupted_y_train,\n",
    "                    epochs=experiment_config[\"pre_train_epochs\"],\n",
    "                    batch_size=experiment_config[\"batch_size\"],\n",
    "                    validation_split=experiment_config[\"holdout_fraction\"],\n",
    "                    verbose=verbosity,\n",
    "                )\n",
    "                print(\"\\t\\tModel pre-training completed\")\n",
    "            \n",
    "            # Now time to actually construct and train the CBM\n",
    "            cbm_model = construct_cbm(\n",
    "                encoder=encoder,\n",
    "                decoder=decoder,\n",
    "                alpha=alpha,\n",
    "                learning_rate=experiment_config[\"learning_rate\"],\n",
    "                num_outputs=experiment_config[\"num_outputs\"],\n",
    "                latent_dims=experiment_config.get(\"latent_dims\", 0),\n",
    "                encoder_output_logits=experiment_config.get(\"encoder_output_logits\", False),\n",
    "            )\n",
    "\n",
    "            early_stopping_monitor = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=experiment_config.get(\n",
    "                    \"early_stop_metric\",\n",
    "                    \"val_concept_accuracy\",\n",
    "                ),\n",
    "                min_delta=experiment_config[\"min_delta\"],\n",
    "                patience=experiment_config[\"patience\"],\n",
    "                restore_best_weights=True,\n",
    "                verbose=2,\n",
    "                mode=experiment_config.get(\n",
    "                    \"early_stop_mode\",\n",
    "                    \"max\",\n",
    "                ),\n",
    "            )\n",
    "            if experiment_config[\"warmup_epochs\"]:\n",
    "                print(\"\\tWarmup training with corrupted samples...\")\n",
    "                cbm_model.fit(\n",
    "                    x=corrupted_x_train,\n",
    "                    y=(corrupted_y_train, corrupted_c_train),\n",
    "                    epochs=experiment_config[\"warmup_epochs\"],\n",
    "                    batch_size=experiment_config[\"batch_size\"],\n",
    "                    validation_split=experiment_config[\"holdout_fraction\"],\n",
    "                    verbose=verbosity,\n",
    "                )\n",
    "                print(\"\\t\\tWarmup training completed\")\n",
    "\n",
    "\n",
    "            print(\"\\tCBM training with corrupted samples...\")\n",
    "            cbm_model.fit(\n",
    "                x=corrupted_x_train,\n",
    "                y=(corrupted_y_train, corrupted_c_train),\n",
    "                epochs=experiment_config[\"max_epochs\"],\n",
    "                batch_size=experiment_config[\"batch_size\"],\n",
    "                callbacks=[\n",
    "                    early_stopping_monitor,\n",
    "                ],\n",
    "                validation_split=experiment_config[\"holdout_fraction\"],\n",
    "                verbose=verbosity,\n",
    "            )\n",
    "            print(\"\\t\\tCBM training completed\")\n",
    "            print(\"\\tSerializing model\")\n",
    "            encoder.save(\n",
    "                os.path.join(\n",
    "                    experiment_config[\"results_dir\"],\n",
    "                    f\"models/encoder_{alpha}_trial_{trial}\"\n",
    "                )\n",
    "            )\n",
    "            decoder.save(\n",
    "                os.path.join(\n",
    "                    experiment_config[\"results_dir\"],\n",
    "                    f\"models/decoder_{alpha}_trial_{trial}\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            print(\"\\tEvaluating model (corrupted data)\")\n",
    "            # First evaluate with corrupted samples\n",
    "            corrupted_test_result = cbm_model.evaluate(\n",
    "                corrupted_x_test,\n",
    "                (\n",
    "                    corrupted_y_test,\n",
    "                    corrupted_c_test[:, :experiment_config[\"num_concepts\"]],\n",
    "                ),\n",
    "                verbose=0,\n",
    "                return_dict=True,\n",
    "            )\n",
    "            corrupted_task_accs.append(\n",
    "                corrupted_test_result['sparse_top_k_categorical_accuracy']\n",
    "                if experiment_config['num_outputs'] > 1 else\n",
    "                corrupted_test_result['binary_accuracy']\n",
    "            )\n",
    "            corrupted_concept_accs.append(corrupted_test_result['concept_accuracy'])\n",
    "            \n",
    "            if experiment_config['num_outputs'] > 1:\n",
    "                # Then lets apply a softmax activation over all the probability\n",
    "                # classes\n",
    "                preds = scipy.special.softmax(cbm_model.predict(corrupted_x_test)[0], axis=-1)\n",
    "                print(\"preds.shape =\", preds.shape)\n",
    "                # And select just the labels that are in fact being used\n",
    "                one_hot_labels = tf.keras.utils.to_categorical(corrupted_y_test)\n",
    "                print(\"one_hot_labels.shape =\", one_hot_labels.shape)\n",
    "                corrupted_aucs.append(sklearn.metrics.roc_auc_score(\n",
    "                    one_hot_labels,\n",
    "                    preds,\n",
    "                    multi_class='ovo',\n",
    "                ))\n",
    "            else:\n",
    "                corrupted_aucs.append(sklearn.metrics.roc_auc_score(\n",
    "                    corrupted_y_test,\n",
    "                    cbm_model.predict(corrupted_x_test)[0],\n",
    "                ))\n",
    "            \n",
    "            print(\n",
    "                f\"\\t\\tCorrupted Test auc = {corrupted_aucs[-1]:.4f}, \"\n",
    "                f\"corrupted test concept accuracy = {corrupted_concept_accs[-1]:.4f}, \"\n",
    "                f\"corrupted task accuracy = {corrupted_task_accs[-1]:.4f}\"\n",
    "            )\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            print(\"\\tEvaluating model (real data)\")\n",
    "            test_result = cbm_model.evaluate(\n",
    "                x_test,\n",
    "                (\n",
    "                    y_test,\n",
    "                    c_test[:, :experiment_config[\"num_concepts\"]],\n",
    "                ),\n",
    "                verbose=0,\n",
    "                return_dict=True,\n",
    "            )\n",
    "            task_accs.append(\n",
    "                test_result['sparse_top_k_categorical_accuracy']\n",
    "                if experiment_config['num_outputs'] > 1 else\n",
    "                test_result['binary_accuracy']\n",
    "            )\n",
    "            concept_accs.append(test_result['concept_accuracy'])\n",
    "\n",
    "            if experiment_config['num_outputs'] > 1:\n",
    "                # Then lets apply a softmax activation over all the probability\n",
    "                # classes\n",
    "                preds = scipy.special.softmax(cbm_model.predict(x_test)[0], axis=-1)\n",
    "                print(\"preds.shape =\", preds.shape)\n",
    "                \n",
    "                # And select just the labels that are in fact being used\n",
    "                one_hot_labels = tf.keras.utils.to_categorical(y_test)\n",
    "                print(\"one_hot_labels.shape =\", one_hot_labels.shape)\n",
    "                aucs.append(sklearn.metrics.roc_auc_score(\n",
    "                    one_hot_labels,\n",
    "                    preds,\n",
    "                    multi_class='ovo',\n",
    "                ))\n",
    "            else:\n",
    "                aucs.append(sklearn.metrics.roc_auc_score(\n",
    "                    y_test,\n",
    "                    cbm_model.predict(x_test)[0],\n",
    "                ))\n",
    "\n",
    "            print(\n",
    "                f\"\\t\\tReal Test auc = {aucs[-1]:.4f}, \"\n",
    "                f\"real test concept accuracy = {concept_accs[-1]:.4f}, \"\n",
    "                f\"real task accuracy = {task_accs[-1]:.4f}\"\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            print(f\"\\t\\tComputing purity score (real data)...\")\n",
    "            c_train_pred = cbm_model.encoder(x_train).numpy()\n",
    "            c_test_pred = cbm_model.encoder(x_test).numpy()\n",
    "\n",
    "            enc = OneHotEncoder(sparse=False)\n",
    "            y_train_one_hot = enc.fit_transform(y_train.reshape(-1, 1))\n",
    "            y_test_one_hot = enc.fit_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "            # END TASK NICHING SCORES\n",
    "            classifier = MLPClassifier((20, 20), random_state=1, max_iter=1000).fit(c_train_pred, y_train_one_hot)\n",
    "            current_niche_impurity_beta_scores = []\n",
    "            current_niche_size_beta_scores = []\n",
    "            # And estimate the area under the curve using the trapezoid method\n",
    "            current_niche_impurity_auc = 0\n",
    "            prev_value_map = {}\n",
    "            delta_beta = experiment_config.get(\"delta_beta\", 0.05)\n",
    "            for beta in np.arange(0.0, 1.0, experiment_config.get(\"delta_beta\", 0.05)):\n",
    "                niches, niching_matrix = niching.niche_finding(c_train_pred, y_train_one_hot, 'corr', threshold=beta)\n",
    "                np_score = niching.niche_impurity(c_test_pred, y_test_one_hot, classifier, niches)\n",
    "                current_niche_impurity_beta_scores.append(np_score['auc_impurity'])\n",
    "                current_niche_size_beta_scores.append(niches.sum(axis=0).mean())\n",
    "                \n",
    "                # And update the area under the curve\n",
    "                if 'niche_impurity' in prev_value_map:\n",
    "                    current_niche_impurity_auc += (\n",
    "                        prev_value_map['niche_impurity'] + np_score['auc_impurity']\n",
    "                    ) * (delta_beta / 2)\n",
    "                prev_value_map['niche_impurity'] = np_score['auc_impurity']\n",
    "            \n",
    "            print(\"\\t\\t\\tReal Task Niche impurity by betas:\", current_niche_impurity_beta_scores)\n",
    "            print(\"\\t\\t\\tReal Task Niche impurity AUC:\", current_niche_impurity_auc)\n",
    "            print(\"\\t\\t\\tReal Task Niche average size:\", current_niche_size_beta_scores)\n",
    "            niche_impurity_aucs.append(current_niche_impurity_auc)\n",
    "            niche_impurity_by_betas.append(current_niche_impurity_beta_scores)\n",
    "            niche_size_by_betas.append(current_niche_size_beta_scores)\n",
    "            \n",
    "            \n",
    "            # CONCEPT TASK NICHING SCORES\n",
    "            classifier = MLPClassifier((20, 20), random_state=1, max_iter=1000).fit(c_train_pred, c_train)\n",
    "            current_niche_impurity_beta_scores = []\n",
    "            current_niche_size_beta_scores = []\n",
    "            # And estimate the area under the curve using the trapezoid method\n",
    "            current_niche_impurity_auc = 0\n",
    "            prev_value_map = {}\n",
    "            delta_beta = experiment_config.get(\"delta_beta\", 0.05)\n",
    "            for beta in np.arange(0.0, 1.0, experiment_config.get(\"delta_beta\", 0.05)):\n",
    "                niches, niching_matrix = niching.niche_finding(c_train_pred, c_train, 'corr', threshold=beta)\n",
    "                np_score = niching.niche_impurity(c_test_pred, c_test, classifier, niches)\n",
    "                current_niche_impurity_beta_scores.append(np_score['auc_impurity'])\n",
    "                current_niche_size_beta_scores.append(niches.sum(axis=0).mean())\n",
    "\n",
    "                # And update the area under the curve\n",
    "                if 'niche_impurity' in prev_value_map:\n",
    "                    current_niche_impurity_auc += (\n",
    "                        prev_value_map['niche_impurity'] + np_score['auc_impurity']\n",
    "                    ) * (delta_beta / 2)\n",
    "                prev_value_map['niche_impurity'] = np_score['auc_impurity']\n",
    "\n",
    "            print(\"\\t\\t\\tReal Concept Niche impurity by betas:\", current_niche_impurity_beta_scores)\n",
    "            print(\"\\t\\t\\tReal Concept Niche impurity AUC:\", current_niche_impurity_auc)\n",
    "            print(\"\\t\\t\\tReal Concept Niche average size:\", current_niche_size_beta_scores)\n",
    "            concept_niche_impurity_aucs.append(current_niche_impurity_auc)\n",
    "            concept_niche_impurity_by_betas.append(current_niche_impurity_beta_scores)\n",
    "            concept_niche_size_by_betas.append(current_niche_size_beta_scores)\n",
    "            \n",
    "            \n",
    "            print(\"\\t\\tComputing real intervention accuracies...\")\n",
    "            current_intervention_task_acc = []\n",
    "            current_intervention_task_auc = []\n",
    "            if experiment_config.get('random_intervention_order', False):\n",
    "                intervention_order = np.random.permutation(experiment_config['num_concepts'])\n",
    "            else:\n",
    "                intervention_order = range(experiment_config['num_concepts'])\n",
    "            for i in range(len(intervention_order) + 1):\n",
    "                corrected_concepts = intervention_order[:i]\n",
    "                intervention_result = cbm_intervention(\n",
    "                    cbm_model=cbm_model,\n",
    "                    x_train=x_train,\n",
    "                    x_test=x_test,\n",
    "                    y_test=y_test,\n",
    "                    c_test=c_test[:, :experiment_config[\"num_concepts\"]],\n",
    "                    intervention_concepts=corrected_concepts,\n",
    "                )\n",
    "                current_intervention_task_acc.append(intervention_result['accuracy'])\n",
    "                current_intervention_task_auc.append(intervention_result['auc'])\n",
    "            \n",
    "            print(\"\\t\\t\\tReal Intervention AUCs:\", current_intervention_task_auc)\n",
    "            print(\"\\t\\t\\tReal Intervention Accuraciess:\", current_intervention_task_acc)\n",
    "            intervention_task_accuracies.append(current_intervention_task_acc)\n",
    "            intervention_task_aucs.append(current_intervention_task_auc)\n",
    "\n",
    "            print(f\"\\t\\tComputing real purity score...\")\n",
    "            soft_acts = (\n",
    "                np.concatenate(cbm_model.encoder(x_test), axis=-1)\n",
    "                if experiment_config[\"latent_dims\"] else c_test_pred\n",
    "            )\n",
    "            purity_score, purity_mat, oracle_mat = purity.norm_purity_score(\n",
    "                c_soft=soft_acts,\n",
    "                c_true=c_test,\n",
    "                output_matrices=True,\n",
    "            )\n",
    "            purity_mats.append(purity_mat)\n",
    "            oracle_mats.append(oracle_mat)\n",
    "            purities.append(purity_score)\n",
    "            print(f\"\\t\\t\\tDone {purity_score:.4f}\")\n",
    "\n",
    "            print(\"\\t\\tComputing real non-oracle purity score...\")\n",
    "        \n",
    "            non_oracle_purities.append(purity.norm_purity_score(\n",
    "                c_soft=soft_acts,\n",
    "                c_true=c_test,\n",
    "                oracle_matrix=construct_trivial_auc_mat(\n",
    "                    experiment_config[\"data_concepts\"]\n",
    "                ),\n",
    "                purity_matrix=purity_mat,\n",
    "            ))\n",
    "            print(f\"\\t\\t\\tDone {non_oracle_purities[-1]:.4f}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(f\"\\t\\tComputing purity score (corrupted data)...\")\n",
    "            corrupted_c_train_pred = cbm_model.encoder(corrupted_x_train).numpy()\n",
    "            corrupted_c_test_pred = cbm_model.encoder(corrupted_x_test).numpy()\n",
    "\n",
    "            enc = OneHotEncoder(sparse=False)\n",
    "            corrupted_y_train_one_hot = enc.fit_transform(corrupted_y_train.reshape(-1, 1))\n",
    "            corrupted_y_test_one_hot = enc.fit_transform(corrupted_y_test.reshape(-1, 1))\n",
    "\n",
    "            classifier = MLPClassifier((20, 20), random_state=1, max_iter=1000).fit(corrupted_c_train_pred, corrupted_y_train_one_hot)\n",
    "            current_niche_impurity_beta_scores = []\n",
    "            current_niche_size_beta_scores = []\n",
    "            # And estimate the area under the curve using the trapezoid method\n",
    "            current_niche_impurity_auc = 0\n",
    "            prev_value_map = {}\n",
    "            delta_beta = experiment_config.get(\"delta_beta\", 0.05)\n",
    "            for beta in np.arange(0.0, 1.0, experiment_config.get(\"delta_beta\", 0.05)):\n",
    "                niches, niching_matrix = niching.niche_finding(corrupted_c_train_pred, corrupted_y_train_one_hot, 'corr', threshold=beta)\n",
    "                np_score = niching.niche_impurity(corrupted_c_test_pred, corrupted_y_test_one_hot, classifier, niches)\n",
    "                current_niche_impurity_beta_scores.append(np_score['auc_impurity'])\n",
    "                current_niche_size_beta_scores.append(niches.sum(axis=0).mean())\n",
    "                \n",
    "                # And update the area under the curve\n",
    "                if 'niche_impurity' in prev_value_map:\n",
    "                    current_niche_impurity_auc += (\n",
    "                        prev_value_map['niche_impurity'] + np_score['auc_impurity']\n",
    "                    ) * (delta_beta / 2)\n",
    "                prev_value_map['niche_impurity'] = np_score['auc_impurity']\n",
    "            \n",
    "            print(\"\\t\\t\\tCorrupted Task Niche impurity by betas:\", current_niche_impurity_beta_scores)\n",
    "            print(\"\\t\\t\\tCorrupted Task Niche impurity AUC:\", current_niche_impurity_auc)\n",
    "            print(\"\\t\\t\\tCorrupted Task Niche average size:\", current_niche_size_beta_scores)\n",
    "            corrupted_niche_impurity_aucs.append(current_niche_impurity_auc)\n",
    "            corrupted_niche_impurity_by_betas.append(current_niche_impurity_beta_scores)\n",
    "            corrupted_niche_size_by_betas.append(current_niche_size_beta_scores)\n",
    "            \n",
    "            \n",
    "            # CONCEPT TASK NICHING SCORES\n",
    "            classifier = MLPClassifier((20, 20), random_state=1, max_iter=1000).fit(corrupted_c_train_pred, corrupted_c_train)\n",
    "            current_niche_impurity_beta_scores = []\n",
    "            current_niche_size_beta_scores = []\n",
    "            # And estimate the area under the curve using the trapezoid method\n",
    "            current_niche_impurity_auc = 0\n",
    "            prev_value_map = {}\n",
    "            delta_beta = experiment_config.get(\"delta_beta\", 0.05)\n",
    "            for beta in np.arange(0.0, 1.0, experiment_config.get(\"delta_beta\", 0.05)):\n",
    "                niches, niching_matrix = niching.niche_finding(corrupted_c_train_pred, corrupted_c_train, 'corr', threshold=beta)\n",
    "                np_score = niching.niche_impurity(corrupted_c_test_pred, corrupted_c_test, classifier, niches)\n",
    "                current_niche_impurity_beta_scores.append(np_score['auc_impurity'])\n",
    "                current_niche_size_beta_scores.append(niches.sum(axis=0).mean())\n",
    "\n",
    "                # And update the area under the curve\n",
    "                if 'niche_impurity' in prev_value_map:\n",
    "                    current_niche_impurity_auc += (\n",
    "                        prev_value_map['niche_impurity'] + np_score['auc_impurity']\n",
    "                    ) * (delta_beta / 2)\n",
    "                prev_value_map['niche_impurity'] = np_score['auc_impurity']\n",
    "\n",
    "            print(\"\\t\\t\\tCorrupted Concept Niche impurity by betas:\", current_niche_impurity_beta_scores)\n",
    "            print(\"\\t\\t\\tCorrupted Concept Niche impurity AUC:\", current_niche_impurity_auc)\n",
    "            print(\"\\t\\t\\tCorrupted Concept Niche average size:\", current_niche_size_beta_scores)\n",
    "            corrupted_concept_niche_impurity_aucs.append(current_niche_impurity_auc)\n",
    "            corrupted_concept_niche_impurity_by_betas.append(current_niche_impurity_beta_scores)\n",
    "            corrupted_concept_niche_size_by_betas.append(current_niche_size_beta_scores)\n",
    "            \n",
    "            \n",
    "            print(\"\\t\\tComputing corrupted intervention accuracies...\")\n",
    "            current_intervention_task_acc = []\n",
    "            current_intervention_task_auc = []\n",
    "            if experiment_config.get('random_intervention_order', False):\n",
    "                intervention_order = np.random.permutation(experiment_config['num_concepts'])\n",
    "            else:\n",
    "                intervention_order = range(experiment_config['num_concepts'])\n",
    "            for i in range(len(intervention_order) + 1):\n",
    "                corrected_concepts = intervention_order[:i]\n",
    "                corrupted_intervention_result = cbm_intervention(\n",
    "                    cbm_model=cbm_model,\n",
    "                    x_train=corrupted_x_train,\n",
    "                    x_test=corrupted_x_test,\n",
    "                    y_test=corrupted_y_test,\n",
    "                    c_test=corrupted_c_test[:, :experiment_config[\"num_concepts\"]],\n",
    "                    intervention_concepts=corrected_concepts,\n",
    "                )\n",
    "                current_intervention_task_acc.append(corrupted_intervention_result['accuracy'])\n",
    "                current_intervention_task_auc.append(corrupted_intervention_result['auc'])\n",
    "            \n",
    "            print(\"\\t\\t\\tCorrupted Intervention AUCs:\", current_intervention_task_auc)\n",
    "            print(\"\\t\\t\\tCorrupted Intervention Accuraciess:\", current_intervention_task_acc)\n",
    "            corrupted_intervention_task_accuracies.append(current_intervention_task_acc)\n",
    "            corrupted_intervention_task_aucs.append(current_intervention_task_auc)\n",
    "\n",
    "            print(f\"\\t\\tComputing corrupted purity score...\")\n",
    "            corrupted_soft_acts = (\n",
    "                np.concatenate(cbm_model.encoder(corrupted_x_test), axis=-1)\n",
    "                if experiment_config[\"latent_dims\"] else corrupted_c_test_pred\n",
    "            )\n",
    "            corrupted_purity_score, corrupted_purity_mat, oracle_mat = purity.norm_purity_score(\n",
    "                c_soft=corrupted_soft_acts,\n",
    "                c_true=corrupted_c_test,\n",
    "                output_matrices=True,\n",
    "                oracle_matrix=oracle_mat,\n",
    "            )\n",
    "            corrupted_purity_mats.append(corrupted_purity_mat)\n",
    "            corrupted_purities.append(corrupted_purity_score)\n",
    "            print(f\"\\t\\t\\tDone {corrupted_purity_score:.4f}\")\n",
    " \n",
    "            \n",
    "            print(\"\\t\\tDone with trial\", trial + 1)\n",
    "\n",
    "        task_acc_mean, task_acc_std = np.mean(task_accs), np.std(task_accs)\n",
    "        experiment_variables[\"task_accuracies\"].append((task_acc_mean, task_acc_std))\n",
    "        print(f\"\\tReal Test task accuracy: {task_acc_mean:.4f} ± {task_acc_std:.4f}\")\n",
    "        \n",
    "        corrupted_task_acc_mean, corrupted_task_acc_std = np.mean(corrupted_task_accs), np.std(corrupted_task_accs)\n",
    "        experiment_variables[\"corrupted_task_accuracies\"].append((corrupted_task_acc_mean, corrupted_task_acc_std))\n",
    "        print(f\"\\tCorrupted Test task accuracy: {corrupted_task_acc_mean:.4f} ± {corrupted_task_acc_std:.4f}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        concept_acc_mean, concept_acc_std = np.mean(concept_accs), np.std(concept_accs)\n",
    "        experiment_variables[\"concept_accuracies\"].append((concept_acc_mean, concept_acc_std))\n",
    "        print(f\"\\tTest concept accuracy: {concept_acc_mean:.4f} ± {concept_acc_std:.4f}\")\n",
    "\n",
    "        corrupted_concept_acc_mean, corrupted_concept_acc_std = np.mean(corrupted_concept_accs), np.std(corrupted_concept_accs)\n",
    "        experiment_variables[\"corrupted_concept_accuracies\"].append((corrupted_concept_acc_mean, corrupted_concept_acc_std))\n",
    "        print(f\"\\tCorrupted Test concept accuracy: {corrupted_concept_acc_mean:.4f} ± {corrupted_concept_acc_std:.4f}\")\n",
    "\n",
    "\n",
    "        \n",
    "        task_auc_mean, task_auc_std = np.mean(aucs), np.std(aucs)\n",
    "        experiment_variables[\"task_aucs\"].append((task_auc_mean, task_auc_std))\n",
    "        print(f\"\\tReal Test task AUC: {task_auc_mean:.4f} ± {task_auc_std:.4f}\")\n",
    "        \n",
    "        corrupted_task_auc_mean, corrupted_task_auc_std = np.mean(corrupted_aucs), np.std(corrupted_aucs)\n",
    "        experiment_variables[\"corrupted_task_aucs\"].append((corrupted_task_auc_mean, corrupted_task_auc_std))\n",
    "        print(f\"\\tCorrupted Test task AUC: {corrupted_task_auc_mean:.4f} ± {corrupted_task_auc_std:.4f}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        purity_mats = np.stack(purity_mats, axis=0)\n",
    "        purity_mat_mean = np.mean(purity_mats, axis=0)\n",
    "        purity_mat_std = np.std(purity_mats, axis=0)\n",
    "        print(\"\\tReal Purity matrix:\")\n",
    "        for i in range(purity_mat_mean.shape[0]):\n",
    "            line = \"\\t\\t\"\n",
    "            for j in range(purity_mat_mean.shape[1]):\n",
    "                line += f'{purity_mat_mean[i, j]:.4f} ± {purity_mat_std[i, j]:.4f}    '\n",
    "            print(line)\n",
    "\n",
    "        experiment_variables[\"purity_matrices\"].append((purity_mat_mean, purity_mat_std))\n",
    "        \n",
    "        corrupted_purity_mats = np.stack(corrupted_purity_mats, axis=0)\n",
    "        corrupted_purity_mat_mean = np.mean(corrupted_purity_mats, axis=0)\n",
    "        corrupted_purity_mat_std = np.std(corrupted_purity_mats, axis=0)\n",
    "        print(\"\\tCorrupted Purity matrix:\")\n",
    "        for i in range(corrupted_purity_mat_mean.shape[0]):\n",
    "            line = \"\\t\\t\"\n",
    "            for j in range(corrupted_purity_mat_mean.shape[1]):\n",
    "                line += f'{corrupted_purity_mat_mean[i, j]:.4f} ± {corrupted_purity_mat_std[i, j]:.4f}    '\n",
    "            print(line)\n",
    "\n",
    "        experiment_variables[\"corrupted_purity_matrices\"].append((corrupted_purity_mat_mean, corrupted_purity_mat_std))\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        oracle_mats = np.stack(oracle_mats, axis=0)\n",
    "        oracle_mat_mean = np.mean(oracle_mats, axis=0)\n",
    "        oracle_mat_std = np.std(oracle_mats, axis=0)\n",
    "        print(\"\\tOracle matrix:\")\n",
    "        for i in range(oracle_mat_mean.shape[0]):\n",
    "            line = \"\\t\\t\"\n",
    "            for j in range(oracle_mat_mean.shape[1]):\n",
    "                line += f'{oracle_mat_mean[i, j]:.4f} ± {oracle_mat_std[i, j]:.4f}    '\n",
    "            print(line)\n",
    "\n",
    "        experiment_variables[\"oracle_matrices\"].append((oracle_mat_mean, oracle_mat_std))\n",
    "\n",
    "        \n",
    "        \n",
    "        purity_mean, purity_std = np.mean(purities), np.std(purities)\n",
    "        experiment_variables[\"purity_scores\"].append((purity_mean, purity_std))\n",
    "        print(f\"\\tReal Purity score: {purity_mean:.4f} ± {purity_std:.4f}\")\n",
    "        \n",
    "        corrupted_purity_mean, corrupted_purity_std = np.mean(corrupted_purities), np.std(corrupted_purities)\n",
    "        experiment_variables[\"corrupted_purity_scores\"].append((corrupted_purity_mean, corrupted_purity_std))\n",
    "        print(f\"\\tCorrupted Purity score: {corrupted_purity_mean:.4f} ± {corrupted_purity_std:.4f}\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        non_oracle_purity_mean, non_oracle_purity_std = np.mean(non_oracle_purities), np.std(non_oracle_purities)\n",
    "        experiment_variables[\"non_oracle_purity_scores\"].append((non_oracle_purity_mean, non_oracle_purity_std))\n",
    "        print(f\"\\tNon-oracle purity score: {non_oracle_purity_mean:.4f} ± {non_oracle_purity_std:.4f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Time for niche impurity scores\n",
    "        niche_impurity_hist = np.stack(niche_impurity_by_betas, axis=0)\n",
    "        niche_impurity_mean = np.mean(niche_impurity_hist, axis=0)\n",
    "        niche_impurity_std = np.std(niche_impurity_hist, axis=0)\n",
    "        experiment_variables[\"niche_impurity_by_betas\"].append((niche_impurity_mean, niche_impurity_std))\n",
    "        line = \"\\tReal Task Niche Impurities by Beta: [\"\n",
    "        for j in range(niche_impurity_mean.shape[0]):\n",
    "            line += f'{niche_impurity_mean[j]:.4f} ± {niche_impurity_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        corrupted_niche_impurity_hist = np.stack(corrupted_niche_impurity_by_betas, axis=0)\n",
    "        corrupted_niche_impurity_mean = np.mean(corrupted_niche_impurity_hist, axis=0)\n",
    "        corrupted_niche_impurity_std = np.std(corrupted_niche_impurity_hist, axis=0)\n",
    "        experiment_variables[\"corrupted_niche_impurity_by_betas\"].append((corrupted_niche_impurity_mean, corrupted_niche_impurity_std))\n",
    "        line = \"\\tCorrupted Task Niche Impurities by Beta: [\"\n",
    "        for j in range(corrupted_niche_impurity_mean.shape[0]):\n",
    "            line += f'{corrupted_niche_impurity_mean[j]:.4f} ± {corrupted_niche_impurity_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        concept_niche_impurity_hist = np.stack(concept_niche_impurity_by_betas, axis=0)\n",
    "        concept_niche_impurity_mean = np.mean(concept_niche_impurity_hist, axis=0)\n",
    "        concept_niche_impurity_std = np.std(concept_niche_impurity_hist, axis=0)\n",
    "        experiment_variables[\"concept_niche_impurity_by_betas\"].append((concept_niche_impurity_mean, concept_niche_impurity_std))\n",
    "        line = \"\\tReal Concept Niche Impurities by Beta: [\"\n",
    "        for j in range(concept_niche_impurity_mean.shape[0]):\n",
    "            line += f'{concept_niche_impurity_mean[j]:.4f} ± {concept_niche_impurity_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        corrupted_concept_niche_impurity_hist = np.stack(corrupted_concept_niche_impurity_by_betas, axis=0)\n",
    "        corrupted_concept_niche_impurity_mean = np.mean(corrupted_concept_niche_impurity_hist, axis=0)\n",
    "        corrupted_concept_niche_impurity_std = np.std(corrupted_concept_niche_impurity_hist, axis=0)\n",
    "        experiment_variables[\"corrupted_concept_niche_impurity_by_betas\"].append((corrupted_concept_niche_impurity_mean, corrupted_concept_niche_impurity_std))\n",
    "        line = \"\\tCorrupted Concept Niche Impurities by Beta: [\"\n",
    "        for j in range(corrupted_concept_niche_impurity_mean.shape[0]):\n",
    "            line += f'{corrupted_concept_niche_impurity_mean[j]:.4f} ± {corrupted_concept_niche_impurity_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        niche_size_hist = np.stack(niche_size_by_betas, axis=0)\n",
    "        niche_size_mean = np.mean(niche_size_hist, axis=0)\n",
    "        niche_size_std = np.std(niche_size_hist, axis=0)\n",
    "        experiment_variables[\"niche_size_by_betas\"].append((niche_size_mean, niche_size_std))\n",
    "        line = \"\\tReal Task Niche Size by Beta: [\"\n",
    "        for j in range(niche_size_mean.shape[0]):\n",
    "            line += f'{niche_size_mean[j]:.4f} ± {niche_size_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        corrupted_niche_size_hist = np.stack(corrupted_niche_size_by_betas, axis=0)\n",
    "        corrupted_niche_size_mean = np.mean(corrupted_niche_size_hist, axis=0)\n",
    "        corrupted_niche_size_std = np.std(corrupted_niche_size_hist, axis=0)\n",
    "        experiment_variables[\"corrupted_niche_size_by_betas\"].append((corrupted_niche_size_mean, corrupted_niche_size_std))\n",
    "        line = \"\\tCorrupted Task Niche Size by Beta: [\"\n",
    "        for j in range(corrupted_niche_size_mean.shape[0]):\n",
    "            line += f'{corrupted_niche_size_mean[j]:.4f} ± {corrupted_niche_size_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        concept_niche_size_hist = np.stack(concept_niche_size_by_betas, axis=0)\n",
    "        concept_niche_size_mean = np.mean(concept_niche_size_hist, axis=0)\n",
    "        concept_niche_size_std = np.std(concept_niche_size_hist, axis=0)\n",
    "        experiment_variables[\"niche_size_by_betas\"].append((concept_niche_size_mean, concept_niche_size_std))\n",
    "        line = \"\\tReal Concept Niche Size by Beta: [\"\n",
    "        for j in range(concept_niche_size_mean.shape[0]):\n",
    "            line += f'{concept_niche_size_mean[j]:.4f} ± {concept_niche_size_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        corrupted_concept_niche_size_hist = np.stack(corrupted_concept_niche_size_by_betas, axis=0)\n",
    "        corrupted_concept_niche_size_mean = np.mean(corrupted_concept_niche_size_hist, axis=0)\n",
    "        corrupted_concept_niche_size_std = np.std(corrupted_concept_niche_size_hist, axis=0)\n",
    "        experiment_variables[\"corrupted_concept_niche_size_by_betas\"].append((corrupted_concept_niche_size_mean, corrupted_concept_niche_size_std))\n",
    "        line = \"\\tCorrupted Concept Niche Size by Beta: [\"\n",
    "        for j in range(corrupted_concept_niche_size_mean.shape[0]):\n",
    "            line += f'{corrupted_concept_niche_size_mean[j]:.4f} ± {corrupted_concept_niche_size_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        niche_impurity_auc_mean, niche_impurity_auc_std = np.mean(niche_impurity_aucs), np.std(niche_impurity_aucs)\n",
    "        experiment_variables[\"niche_impurity_aucs\"].append((niche_impurity_auc_mean, niche_impurity_auc_std))\n",
    "        print(f\"\\tReal Task Niche impurity AUC: {niche_impurity_auc_mean:.4f} ± {niche_impurity_auc_std:.4f}\")\n",
    "        \n",
    "        corrupted_niche_impurity_auc_mean, corrupted_niche_impurity_auc_std = np.mean(corrupted_niche_impurity_aucs), np.std(corrupted_niche_impurity_aucs)\n",
    "        experiment_variables[\"corrupted_niche_impurity_aucs\"].append((corrupted_niche_impurity_auc_mean, corrupted_niche_impurity_auc_std))\n",
    "        print(f\"\\tCorrupted Task Niche impurity AUC: {corrupted_niche_impurity_auc_mean:.4f} ± {corrupted_niche_impurity_auc_std:.4f}\")\n",
    "        \n",
    "        concept_niche_impurity_auc_mean, concept_niche_impurity_auc_std = np.mean(concept_niche_impurity_aucs), np.std(concept_niche_impurity_aucs)\n",
    "        experiment_variables[\"concept_niche_impurity_aucs\"].append((concept_niche_impurity_auc_mean, concept_niche_impurity_auc_std))\n",
    "        print(f\"\\tReal Concept Niche impurity AUC: {concept_niche_impurity_auc_mean:.4f} ± {concept_niche_impurity_auc_std:.4f}\")\n",
    "        \n",
    "        corrupted_concept_niche_impurity_auc_mean, corrupted_concept_niche_impurity_auc_std = np.mean(corrupted_concept_niche_impurity_aucs), np.std(corrupted_concept_niche_impurity_aucs)\n",
    "        experiment_variables[\"corrupted_concept_niche_impurity_aucs\"].append((corrupted_concept_niche_impurity_auc_mean, corrupted_concept_niche_impurity_auc_std))\n",
    "        print(f\"\\tCorrupted Concept Niche impurity AUC: {corrupted_concept_niche_impurity_auc_mean:.4f} ± {corrupted_concept_niche_impurity_auc_std:.4f}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Finally, we end with intervention accuracies\n",
    "        interventaion_auc_hist = np.stack(intervention_task_aucs, axis=0)\n",
    "        interventaion_auc_mean = np.mean(interventaion_auc_hist, axis=0)\n",
    "        interventaion_auc_std = np.std(interventaion_auc_hist, axis=0)\n",
    "        experiment_variables[\"intervention_task_aucs\"].append((interventaion_auc_mean, interventaion_auc_std))\n",
    "        line = \"\\tReal Intervention AUCs: [\"\n",
    "        for j in range(interventaion_auc_mean.shape[0]):\n",
    "            line += f'{interventaion_auc_mean[j]:.4f} ± {interventaion_auc_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        # Finally, we end with intervention accuracies\n",
    "        corrupted_interventaion_auc_hist = np.stack(corrupted_intervention_task_aucs, axis=0)\n",
    "        corrupted_interventaion_auc_mean = np.mean(corrupted_interventaion_auc_hist, axis=0)\n",
    "        corrupted_interventaion_auc_std = np.std(corrupted_interventaion_auc_hist, axis=0)\n",
    "        experiment_variables[\"corrupted_intervention_task_aucs\"].append((corrupted_interventaion_auc_mean, corrupted_interventaion_auc_std))\n",
    "        line = \"\\tCorrupted Intervention AUCs: [\"\n",
    "        for j in range(corrupted_interventaion_auc_mean.shape[0]):\n",
    "            line += f'{corrupted_interventaion_auc_mean[j]:.4f} ± {corrupted_interventaion_auc_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        interventaion_acc_hist = np.stack(intervention_task_accuracies, axis=0)\n",
    "        interventaion_acc_mean = np.mean(interventaion_acc_hist, axis=0)\n",
    "        interventaion_acc_std = np.std(interventaion_acc_hist, axis=0)\n",
    "        experiment_variables[\"intervention_task_accuracies\"].append((interventaion_acc_mean, interventaion_acc_std))\n",
    "        line = \"\\tIntervention Accuracies: [\"\n",
    "        for j in range(interventaion_acc_mean.shape[0]):\n",
    "            line += f'{interventaion_acc_mean[j]:.4f} ± {interventaion_acc_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        corrupted_interventaion_acc_hist = np.stack(corrupted_intervention_task_accuracies, axis=0)\n",
    "        corrupted_interventaion_acc_mean = np.mean(corrupted_interventaion_acc_hist, axis=0)\n",
    "        corrupted_interventaion_acc_std = np.std(corrupted_interventaion_acc_hist, axis=0)\n",
    "        experiment_variables[\"corrupted_intervention_task_accuracies\"].append((corrupted_interventaion_acc_mean, corrupted_interventaion_acc_std))\n",
    "        line = \"\\tCorrupted Intervention Accuracies: [\"\n",
    "        for j in range(corrupted_interventaion_acc_mean.shape[0]):\n",
    "            line += f'{corrupted_interventaion_acc_mean[j]:.4f} ± {corrupted_interventaion_acc_std[j]:.4f},  '\n",
    "        print(line + \"]\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Increase the experiment counter\n",
    "        experiment_variables[\"current_experiment_idx\"] += 1\n",
    "\n",
    "        # And serialize the results\n",
    "        joblib.dump(\n",
    "            experiment_variables,\n",
    "            os.path.join(experiment_config[\"results_dir\"], 'results.joblib'),\n",
    "        )\n",
    "    return experiment_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(purity)\n",
    "reload(CBM)\n",
    "\n",
    "############################################################################\n",
    "## Experiment config\n",
    "############################################################################\n",
    "\n",
    "color_random_from_probs_experiment_config = dict(\n",
    "    trials=5,\n",
    "    batch_size=64 if USE_DSPRITES else 32,\n",
    "    max_epochs=100,\n",
    "    pre_train_epochs=0,\n",
    "    warmup_epochs=0,\n",
    "    learning_rate=1e-3,\n",
    "    encoder_filter_groups=[\n",
    "        [(8, (7, 7))],\n",
    "        [(16, (5, 5))],\n",
    "        [(32, (3, 3))],\n",
    "        [(64, (3, 3))]\n",
    "    ],\n",
    "    encoder_units=[64, 64],\n",
    "    decoder_units=[64, 64],\n",
    "    alpha_values=[0.1, 10],\n",
    "\n",
    "    latent_decoder_units=[64, 64],\n",
    "    predictor_max_epochs=100,\n",
    "    concept_predictor_max_epochs=100,\n",
    "    \n",
    "    drop_prob=0.5,\n",
    "    max_pool_window=(2,2),\n",
    "    pax_pool_stride=2,\n",
    "    num_outputs=(\n",
    "        len(set(color_random_corrupted_data_train[1])) if len(set(color_random_corrupted_data_train[1])) > 2\n",
    "        else 1\n",
    "    ),\n",
    "    concept_cardinality=[1 for _ in range(color_random_corrupted_data_train[2].shape[-1])],\n",
    "    patience=float(\"inf\"),\n",
    "    min_delta=1e-5,\n",
    "    results_dir=os.path.join(RESULTS_DIR, \"cbm/color_random_base_from_probs\"),\n",
    "    input_shape=color_random_corrupted_data_train[0].shape[1:],\n",
    "    num_concepts=color_random_corrupted_data_train[2].shape[-1],\n",
    "    latent_dims=0,\n",
    "    holdout_fraction=0.1,\n",
    "    verbosity=0,\n",
    "    early_stop_metric=\"val_concept_accuracy\",\n",
    "    early_stop_mode=\"max\",\n",
    "    encoder_output_logits=False,\n",
    "    delta_beta=0.05,\n",
    ")\n",
    "\n",
    "############################################################################\n",
    "## Experiment run\n",
    "############################################################################\n",
    "\n",
    "color_random_from_probs_results = cbm_mixed_capacity_intervention_experiment_loop(\n",
    "    train_data=data_train,\n",
    "    corrupted_train_data=color_random_corrupted_data_train,\n",
    "    test_data=data_test,\n",
    "    corrupted_test_data=color_random_corrupted_data_test,\n",
    "    experiment_config=color_random_from_probs_experiment_config,\n",
    "    load_from_cache=True,\n",
    ")\n",
    "print(\"task_accuracies:\", color_random_from_probs_results[\"task_accuracies\"])\n",
    "print(\"corrupted_task_accuracies:\", color_random_from_probs_results[\"corrupted_task_accuracies\"])\n",
    "print(\"concept_accuracies:\", color_random_from_probs_results[\"concept_accuracies\"])\n",
    "print(\"corrupted_concept_accuracies:\", color_random_from_probs_results[\"corrupted_concept_accuracies\"])\n",
    "print(\"task_aucs:\", color_random_from_probs_results[\"task_aucs\"])\n",
    "print(\"purity_scores:\", color_random_from_probs_results[\"purity_scores\"])\n",
    "print(\"corrupted_purity_scores:\", color_random_from_probs_results[\"corrupted_purity_scores\"])\n",
    "print(\"concept_niche_impurity_aucs:\", color_random_from_probs_results[\"concept_niche_impurity_aucs\"])\n",
    "print(\"corrupted_concept_niche_impurity_aucs:\", color_random_from_probs_results[\"corrupted_concept_niche_impurity_aucs\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(purity)\n",
    "reload(CBM)\n",
    "\n",
    "############################################################################\n",
    "## Experiment config\n",
    "############################################################################\n",
    "\n",
    "base_color_experiment_config = dict(\n",
    "    trials=5,\n",
    "    batch_size=64 if USE_DSPRITES else 32,\n",
    "    max_epochs=100,\n",
    "    pre_train_epochs=0,\n",
    "    warmup_epochs=0,\n",
    "    learning_rate=1e-3,\n",
    "    encoder_filter_groups=[\n",
    "        [(8, (7, 7))],\n",
    "        [(16, (5, 5))],\n",
    "        [(32, (3, 3))],\n",
    "        [(64, (3, 3))]\n",
    "    ],\n",
    "    encoder_units=[64, 64],\n",
    "    decoder_units=[64, 64],\n",
    "    alpha_values=[0.0, 0.01, 0.1, 1], #, 10],\n",
    "\n",
    "    latent_decoder_units=[64, 64],\n",
    "    predictor_max_epochs=100,\n",
    "    concept_predictor_max_epochs=100,\n",
    "    \n",
    "    drop_prob=0.5,\n",
    "    max_pool_window=(2,2),\n",
    "    pax_pool_stride=2,\n",
    "    num_outputs=(\n",
    "        len(set(data_train[1])) if len(set(data_train[1])) > 2\n",
    "        else 1\n",
    "    ),\n",
    "    concept_cardinality=[1 for _ in range(data_train[2].shape[-1])],\n",
    "    patience=float(\"inf\"),\n",
    "    min_delta=1e-5,\n",
    "    results_dir=os.path.join(RESULTS_DIR, \"cbm/base_color\"),\n",
    "    input_shape=data_train[0].shape[1:],\n",
    "    num_concepts=data_train[2].shape[-1],\n",
    "    latent_dims=0,\n",
    "    holdout_fraction=0.1,\n",
    "    verbosity=0,\n",
    "    early_stop_metric=\"val_concept_accuracy\",\n",
    "    early_stop_mode=\"max\",\n",
    "    encoder_output_logits=False,\n",
    "    delta_beta=0.05,\n",
    ")\n",
    "\n",
    "############################################################################\n",
    "## Experiment run\n",
    "############################################################################\n",
    "\n",
    "base_color_results = cbm_mixed_capacity_intervention_experiment_loop(\n",
    "    train_data=data_train,\n",
    "    corrupted_train_data=color_corrupted_data_train,\n",
    "    test_data=data_test,\n",
    "    corrupted_test_data=color_corrupted_data_test,\n",
    "    experiment_config=base_color_experiment_config,\n",
    "    load_from_cache=True,\n",
    ")\n",
    "print(\"task_accuracies:\", base_color_results[\"task_accuracies\"])\n",
    "print(\"corrupted_task_accuracies:\", base_color_results[\"corrupted_task_accuracies\"])\n",
    "print(\"concept_accuracies:\", base_color_results[\"concept_accuracies\"])\n",
    "print(\"corrupted_concept_accuracies:\", base_color_results[\"corrupted_concept_accuracies\"])\n",
    "print(\"task_aucs:\", base_color_results[\"task_aucs\"])\n",
    "print(\"purity_scores:\", base_color_results[\"purity_scores\"])\n",
    "print(\"corrupted_purity_scores:\", base_color_results[\"purity_scores\"])\n",
    "print(\"corrupted_concept_niche_impurity_aucs:\", base_color_results[\"corrupted_concept_niche_impurity_aucs\"])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "purity_dsprites.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
